{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.read_csv(\"./Data/check_fraud.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307664, 615)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>TXN_UID</th>\n",
       "      <th>FACE_AMOUNT</th>\n",
       "      <th>NAT_POSITIVE_GRADE</th>\n",
       "      <th>SEGMENT</th>\n",
       "      <th>char_CHECK_NO</th>\n",
       "      <th>ID_STATION_STATE</th>\n",
       "      <th>LOCAL_HOUR</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MOD_FACE_AMT</th>\n",
       "      <th>...</th>\n",
       "      <th>C_R_AV_APP_D_12M_14D_RT</th>\n",
       "      <th>C_R_AV_APP_D_6M_7D_RT</th>\n",
       "      <th>C_R_DLY_APPR_24M_14D_RT</th>\n",
       "      <th>C_R_DLY_APPR_12M_14D_RT</th>\n",
       "      <th>C_R_DLY_APPR_6M_3M_RT</th>\n",
       "      <th>C_STD_C_AVG_TIME_24M_RT</th>\n",
       "      <th>C_STD_C_AVG_TIME_6M_RT</th>\n",
       "      <th>C_STD_C_AVG_TIME_30D_RT</th>\n",
       "      <th>C_STD_C_AVG_TIME_18D_RT</th>\n",
       "      <th>C_STD_C_AVG_TIME_14D_RT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUP_PRES_IND</th>\n",
       "      <th>LOSS_IND</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>250000</td>\n",
       "      <td>250000</td>\n",
       "      <td>164837</td>\n",
       "      <td>250000</td>\n",
       "      <td>250000</td>\n",
       "      <td>250000</td>\n",
       "      <td>250000</td>\n",
       "      <td>250000</td>\n",
       "      <td>247134</td>\n",
       "      <td>250000</td>\n",
       "      <td>...</td>\n",
       "      <td>217937</td>\n",
       "      <td>206962</td>\n",
       "      <td>231899</td>\n",
       "      <td>217937</td>\n",
       "      <td>155036</td>\n",
       "      <td>219757</td>\n",
       "      <td>183641</td>\n",
       "      <td>115755</td>\n",
       "      <td>69038</td>\n",
       "      <td>55431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>701</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2571</td>\n",
       "      <td>2615</td>\n",
       "      <td>...</td>\n",
       "      <td>1839</td>\n",
       "      <td>1582</td>\n",
       "      <td>2149</td>\n",
       "      <td>1839</td>\n",
       "      <td>1034</td>\n",
       "      <td>1880</td>\n",
       "      <td>1173</td>\n",
       "      <td>506</td>\n",
       "      <td>320</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 612 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       TXN_UID  FACE_AMOUNT  NAT_POSITIVE_GRADE  SEGMENT  \\\n",
       "DUP_PRES_IND LOSS_IND                                                      \n",
       "-1           -1         250000       250000              164837   250000   \n",
       " 1            1           2615         2615                 701     2615   \n",
       "\n",
       "                       char_CHECK_NO  ID_STATION_STATE  LOCAL_HOUR  \\\n",
       "DUP_PRES_IND LOSS_IND                                                \n",
       "-1           -1               250000            250000      250000   \n",
       " 1            1                 2615              2615        2615   \n",
       "\n",
       "                       DAY_OF_WEEK     AGE  MOD_FACE_AMT  ...  \\\n",
       "DUP_PRES_IND LOSS_IND                                     ...   \n",
       "-1           -1             250000  247134        250000  ...   \n",
       " 1            1               2615    2571          2615  ...   \n",
       "\n",
       "                       C_R_AV_APP_D_12M_14D_RT  C_R_AV_APP_D_6M_7D_RT  \\\n",
       "DUP_PRES_IND LOSS_IND                                                   \n",
       "-1           -1                         217937                 206962   \n",
       " 1            1                           1839                   1582   \n",
       "\n",
       "                       C_R_DLY_APPR_24M_14D_RT  C_R_DLY_APPR_12M_14D_RT  \\\n",
       "DUP_PRES_IND LOSS_IND                                                     \n",
       "-1           -1                         231899                   217937   \n",
       " 1            1                           2149                     1839   \n",
       "\n",
       "                       C_R_DLY_APPR_6M_3M_RT  C_STD_C_AVG_TIME_24M_RT  \\\n",
       "DUP_PRES_IND LOSS_IND                                                   \n",
       "-1           -1                       155036                   219757   \n",
       " 1            1                         1034                     1880   \n",
       "\n",
       "                       C_STD_C_AVG_TIME_6M_RT  C_STD_C_AVG_TIME_30D_RT  \\\n",
       "DUP_PRES_IND LOSS_IND                                                    \n",
       "-1           -1                        183641                   115755   \n",
       " 1            1                          1173                      506   \n",
       "\n",
       "                       C_STD_C_AVG_TIME_18D_RT  C_STD_C_AVG_TIME_14D_RT  \n",
       "DUP_PRES_IND LOSS_IND                                                    \n",
       "-1           -1                          69038                    55431  \n",
       " 1            1                            320                      250  \n",
       "\n",
       "[2 rows x 612 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pull out approved volume to fit and validate the models on\n",
    "approve_vol = analysis_df[(analysis_df['RC4_AUTH_IND'] == 'A') & ((analysis_df['DUP_PRES_IND'] == 1) | (analysis_df['LOSS_IND'] == -1))]\n",
    "approve_vol.drop(columns = 'RC4_AUTH_IND', inplace = True)\n",
    "approve_vol.groupby(['DUP_PRES_IND','LOSS_IND']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out target var, need to convert the -1's to 0's for the neural net\n",
    "y_train = approve_vol[approve_vol['SEGMENT'] == 'DEV'].DUP_PRES_IND\n",
    "y_val = approve_vol[approve_vol['SEGMENT'] == 'VDT'].DUP_PRES_IND\n",
    "\n",
    "y_train_bin = y_train.replace(-1, 0)\n",
    "y_val_bin = y_val.replace(-1, 0)\n",
    "\n",
    "X_train = approve_vol[approve_vol['SEGMENT'] == 'DEV'].drop(columns = ['TXN_UID','SEGMENT','DUP_PRES_IND','LOSS_IND'])\n",
    "X_val = approve_vol[approve_vol['SEGMENT'] == 'VDT'].drop(columns = ['TXN_UID','SEGMENT','DUP_PRES_IND','LOSS_IND'])\n",
    "\n",
    "#I also need a data frame of all transactions, including declines, that I can score for deeper analysis\n",
    "X_deep_dive = analysis_df.drop(columns = ['TXN_UID','SEGMENT','DUP_PRES_IND','LOSS_IND','RC4_AUTH_IND'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Target: 1178 , Val Target: 1437\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Target: {} , Val Target: {}\".format(y_train_bin.sum(),y_val_bin.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FACE_AMOUNT',\n",
       " 'LOCAL_HOUR',\n",
       " 'AGE',\n",
       " 'MOD_FACE_AMT',\n",
       " 'FA_ROUND',\n",
       " 'M_DAYS_FIRST_DECL_L1',\n",
       " 'M_ATT_CNT_60D_L1',\n",
       " 'M_ATT_CNT_90D_L1',\n",
       " 'M_ATT_DLR_3D_L1',\n",
       " 'M_ATT_DLR_30D_L1',\n",
       " 'M_ATT_DLR_60D_L1',\n",
       " 'M_ATT_DLR_90D_L1',\n",
       " 'M_APPR_CNT_7D_L1',\n",
       " 'M_APPR_CNT_30D_L1',\n",
       " 'M_APPR_DLR_60D_L1',\n",
       " 'M_DECL_CNT_3D_L1',\n",
       " 'M_DECL_CNT_7D_L1',\n",
       " 'M_DECL_CNT_90D_L1',\n",
       " 'M_DECL_DLR_30D_L1',\n",
       " 'M_DECL_DLR_60D_L1',\n",
       " 'M_UNIT_GLR_60D_L1',\n",
       " 'M_UNIT_GLR_30D_L1',\n",
       " 'M_DLR_GLR_60D_L1',\n",
       " 'M_APPR_DLR_90D_L3',\n",
       " 'M_APPR_CNT_60D_L3',\n",
       " 'M_APPR_DLR_60D_L3',\n",
       " 'M_APPR_CNT_60D_L7',\n",
       " 'M_APP_CKNO_SFA_X_90D_L1',\n",
       " 'M_DECL_RATE_90D_L1',\n",
       " 'M_FA_DFAV_APPR_90D_L1',\n",
       " 'M_FA_DFMX_APPR_90D_L1',\n",
       " 'M_APPR_FA_SFA_60D_L1',\n",
       " 'M_APPR_CKNO_SFA_60D_L1',\n",
       " 'M_FA_DFAV_APPR_60D_L1',\n",
       " 'M_APP_CKNO_SFA_X_30D_L1',\n",
       " 'M_FA_DFAV_APPR_30D_L1',\n",
       " 'M_FA_PDFAV_APPR_30D_L1',\n",
       " 'M_APPR_FA_SFA_7D_L1',\n",
       " 'M_APP_CKNO_SFA_X_7D_L1',\n",
       " 'M_FA_PDFMX_APPR_7D_L1',\n",
       " 'M_APPR_FA_SFA_3D_L1',\n",
       " 'M_DECL_DLR_RATE_3D_L1',\n",
       " 'M_FA_DFAV_APPR_3D_L1',\n",
       " 'M_FA_PDFAV_APPR_3D_L1',\n",
       " 'M_FA_PDFMX_APPR_3D_L1',\n",
       " 'M_APPR_FA_SFA_1D_L1',\n",
       " 'M_FA_PDFAV_APPR_1D_L1',\n",
       " 'CM_CHKNO_INCR_TRM_RT',\n",
       " 'C_MIN_LAST_APPR_RT',\n",
       " 'C_DAY_LAST_APPR_RT',\n",
       " 'C_DAY_FIRST_APPR_RT',\n",
       " 'C_MIN_FIRST_DECL_RT',\n",
       " 'C_MIN_HIGHRISK_DECL_RT',\n",
       " 'C_MIN_LAST_P_APPR_RT',\n",
       " 'C_DAY_LAST_P_APPR_RT',\n",
       " 'C_DAY_FIRST_P_APPR_RT',\n",
       " 'C_MIN_LAST_G_APPR_RT',\n",
       " 'C_MIN_FIRST_G_APPR_RT',\n",
       " 'C_DAY_FIRST_G_APPR_RT',\n",
       " 'CM_MIN_FIRST_APPR_RT',\n",
       " 'C_ATT_CNT_24M_RT',\n",
       " 'C_MAX_ATT_FA_24M_RT',\n",
       " 'C_SAME_Z4_ATT_24M_RT',\n",
       " 'CM_MAX_ATT_FA_24M_RT',\n",
       " 'C_APPR_DLR_24M_RT',\n",
       " 'C_MAX_APPR_FA_24M_RT',\n",
       " 'C_UNPD_CLM_DLR_24M_RT',\n",
       " 'C_NLR_24M_RT',\n",
       " 'C_STA_APPR_CNT_24M_RT',\n",
       " 'C_Z5_APPR_CNT_24M_RT',\n",
       " 'C_SAME_Z4_APPR_24M_RT',\n",
       " 'C_SAME_Z3_APPR_24M_RT',\n",
       " 'C_DECL_DLR_24M_RT',\n",
       " 'C_DECL_DLR_24M_EX_RT',\n",
       " 'C_Z5_DECL_24M_RT',\n",
       " 'C_SAME_STR_DECL_24M_RT',\n",
       " 'C_SAME_Z5_DECL_24M_RT',\n",
       " 'C_SAME_Z3_DECL_24M_RT',\n",
       " 'CM_DECL_CNT_24M_RT',\n",
       " 'C_P_APPR_DLR_24M_RT',\n",
       " 'C_SAME_STR_P_APP_24M_RT',\n",
       " 'C_PAID_P_CLM_CNT_24M_RT',\n",
       " 'C_P_NLR_24M_RT',\n",
       " 'C_G_GLR_24M_RT',\n",
       " 'C_MAX_T_FA_APPR_24M_RT',\n",
       " 'C_STD_F_AVG_FA_24M_RT',\n",
       " 'C_STD_T_F_AVG_FA_24M_RT',\n",
       " 'CM_STD_AVG_AP_FA_24M_RT',\n",
       " 'C_PD_MAX_FA_24M_RT',\n",
       " 'C_PD_MAX_P_FA_24M_RT',\n",
       " 'C_D_MAX_G_FA_24M_RT',\n",
       " 'C_PD_MAX_T_FA_24M_RT',\n",
       " 'CM_D_MAX_AP_FA_24M_RT',\n",
       " 'CM_PD_MAX_AP_FA_24M_RT',\n",
       " 'C_D_FA_AVG_24M_RT',\n",
       " 'C_P_STN_APPR_24M_RT_IND',\n",
       " 'C_G_STN_APPR_24M_RT_IND',\n",
       " 'C_ATT_CNT_18M_RT',\n",
       " 'C_ATT_DLR_18M_RT',\n",
       " 'C_STD_ATT_FA_18M_RT',\n",
       " 'C_STA_ATT_CNT_18M_RT',\n",
       " 'C_SAME_CHN_ATT_18M_RT',\n",
       " 'C_SAME_Z4_ATT_18M_RT',\n",
       " 'C_SAME_Z3_ATT_18M_RT',\n",
       " 'CM_ATT_CNT_18M_RT',\n",
       " 'CM_MAX_ATT_FA_18M_RT',\n",
       " 'C_APPR_CNT_18M_RT',\n",
       " 'C_UNPD_CLM_CNT_18M_RT',\n",
       " 'CM_APPR_CNT_18M_RT',\n",
       " 'CM_MAX_APPR_FA_18M_RT',\n",
       " 'C_DECL_DLR_18M_EX_RT',\n",
       " 'C_STR_CNT_DECL_SSN_18M_RT',\n",
       " 'C_Z5_DECL_18M_RT',\n",
       " 'C_SAME_CHN_DECL_18M_RT',\n",
       " 'C_SAME_Z5_DECL_18M_RT',\n",
       " 'C_MAX_P_FA_APPR_18M_RT',\n",
       " 'C_PAID_P_CLM_CNT_18M_RT',\n",
       " 'C_UNPD_P_CLM_DLR_18M_RT',\n",
       " 'C_G_APPR_CNT_18M_RT',\n",
       " 'C_SAME_STR_G_APP_18M_RT',\n",
       " 'C_PAID_G_CLM_DLR_18M_RT',\n",
       " 'C_UNPD_G_CLM_DLR_18M_RT',\n",
       " 'C_G_GLR_18M_RT',\n",
       " 'C_T_APPR_CNT_18M_RT',\n",
       " 'C_SAME_STR_T_APP_18M_RT',\n",
       " 'C_UNPD_T_CLM_CNT_18M_RT',\n",
       " 'C_T_GLR_18M_RT',\n",
       " 'C_T_NLR_18M_RT',\n",
       " 'CM_STD_AVG_FA_18M_RT',\n",
       " 'C_D_MAX_G_FA_18M_RT',\n",
       " 'C_PD_MAX_G_FA_18M_RT',\n",
       " 'C_PD_MAX_T_FA_18M_RT',\n",
       " 'CM_D_MAX_FA_18M_RT',\n",
       " 'C_DLR_DECL_RATE_18M_RT',\n",
       " 'C_FA_PD_AVG_18M_RT',\n",
       " 'C_G_STN_APPR_18M_RT_IND',\n",
       " 'C_T_STN_APPR_18M_RT_IND',\n",
       " 'C_ATT_DLR_12M_RT',\n",
       " 'C_SAME_Z3_ATT_12M_RT',\n",
       " 'CM_ATT_CNT_12M_RT',\n",
       " 'C_APPR_DLR_12M_RT',\n",
       " 'C_UNPD_CLM_DLR_12M_RT',\n",
       " 'C_GLR_12M_RT',\n",
       " 'C_NLR_12M_RT',\n",
       " 'C_STA_APPR_CNT_12M_RT',\n",
       " 'C_SAME_STR_APPR_12M_RT',\n",
       " 'C_SAME_Z5_APPR_12M_RT',\n",
       " 'CM_APPR_CNT_12M_RT',\n",
       " 'C_DECL_CNT_12M_EX_RT',\n",
       " 'C_CHN_DECL_CNT_12M_RT',\n",
       " 'C_Z5_DECL_12M_RT',\n",
       " 'C_SAME_STR_DECL_12M_RT',\n",
       " 'C_P_APPR_CNT_12M_RT',\n",
       " 'C_MAX_P_FA_APPR_12M_RT',\n",
       " 'C_UNPD_P_CLM_CNT_12M_RT',\n",
       " 'C_P_GLR_12M_RT',\n",
       " 'C_P_NLR_12M_RT',\n",
       " 'C_MAX_G_FA_APPR_12M_RT',\n",
       " 'C_SAME_STR_G_APP_12M_RT',\n",
       " 'C_PAID_G_CLM_DLR_12M_RT',\n",
       " 'C_UNPD_G_CLM_CNT_12M_RT',\n",
       " 'C_UNPD_G_CLM_DLR_12M_RT',\n",
       " 'C_SAME_STR_T_APP_12M_RT',\n",
       " 'C_T_GLR_12M_RT',\n",
       " 'C_STD_G_F_AVG_FA_12M_RT',\n",
       " 'C_D_MAX_FA_12M_RT',\n",
       " 'C_PD_MAX_FA_12M_RT',\n",
       " 'C_D_MAX_P_FA_12M_RT',\n",
       " 'C_PD_MAX_T_FA_12M_RT',\n",
       " 'CM_PD_MAX_FA_12M_RT',\n",
       " 'CM_D_MAX_AP_FA_12M_RT',\n",
       " 'C_UNIT_DECL_RATE_12M_RT',\n",
       " 'C_DLR_DECL_RATE_12M_RT',\n",
       " 'C_FA_PD_AVG_12M_RT',\n",
       " 'C_ATT_DLR_6M_RT',\n",
       " 'CM_MAX_ATT_FA_6M_RT',\n",
       " 'C_APPR_CNT_6M_RT',\n",
       " 'C_STD_APPR_FA_6M_RT',\n",
       " 'C_PAID_CLM_CNT_6M_RT',\n",
       " 'C_UNPD_CLM_CNT_6M_RT',\n",
       " 'C_GLR_6M_RT',\n",
       " 'C_NLR_6M_RT',\n",
       " 'C_STA_APPR_CNT_6M_RT',\n",
       " 'C_SAME_CHN_APPR_6M_RT',\n",
       " 'C_SAME_STR_APPR_6M_RT',\n",
       " 'C_DECL_DLR_6M_EX_RT',\n",
       " 'C_CHN_DECL_CNT_6M_RT',\n",
       " 'C_STR_CNT_DECL_SSN_6M_RT',\n",
       " 'C_SAME_CHN_DECL_6M_RT',\n",
       " 'CM_DECL_CNT_6M_RT',\n",
       " 'C_P_APPR_CNT_6M_RT',\n",
       " 'C_UNPD_P_CLM_CNT_6M_RT',\n",
       " 'C_UNPD_P_CLM_DLR_6M_RT',\n",
       " 'C_G_APPR_DLR_6M_RT',\n",
       " 'C_MAX_G_FA_APPR_6M_RT',\n",
       " 'C_SAME_STR_G_APP_6M_RT',\n",
       " 'C_PAID_G_CLM_CNT_6M_RT',\n",
       " 'C_PAID_G_CLM_DLR_6M_RT',\n",
       " 'C_UNPD_G_CLM_DLR_6M_RT',\n",
       " 'C_G_GLR_6M_RT',\n",
       " 'C_G_NLR_6M_RT',\n",
       " 'C_MAX_T_FA_APPR_6M_RT',\n",
       " 'C_PAID_T_CLM_CNT_6M_RT',\n",
       " 'C_UNPD_T_CLM_DLR_6M_RT',\n",
       " 'C_CLM_DLR_6M_RT',\n",
       " 'C_STD_F_AVG_FA_6M_RT',\n",
       " 'C_STD_G_F_AVG_FA_6M_RT',\n",
       " 'CM_STD_AVG_AP_FA_6M_RT',\n",
       " 'C_PD_MAX_FA_6M_RT',\n",
       " 'C_D_MAX_P_FA_6M_RT',\n",
       " 'C_PD_MAX_T_FA_6M_RT',\n",
       " 'CM_D_MAX_FA_6M_RT',\n",
       " 'CM_D_MAX_AP_FA_6M_RT',\n",
       " 'C_FA_PD_AVG_6M_RT',\n",
       " 'C_ATT_CNT_3M_RT',\n",
       " 'C_ATT_DLR_3M_RT',\n",
       " 'C_STD_ATT_FA_3M_RT',\n",
       " 'C_Z5_ATT_CNT_3M_RT',\n",
       " 'C_SAME_STR_ATT_3M_RT',\n",
       " 'C_SAME_Z4_ATT_3M_RT',\n",
       " 'C_SAME_Z3_ATT_3M_RT',\n",
       " 'CM_ATT_CNT_3M_RT',\n",
       " 'C_APPR_DLR_3M_RT',\n",
       " 'C_MAX_APPR_FA_3M_RT',\n",
       " 'C_PAID_CLM_DLR_3M_RT',\n",
       " 'C_UNPD_CLM_CNT_3M_RT',\n",
       " 'C_SAME_STR_APPR_3M_RT',\n",
       " 'CM_MAX_APPR_FA_3M_RT',\n",
       " 'C_CHN_DECL_CNT_3M_RT',\n",
       " 'C_STR_CNT_DECL_SSN_3M_RT',\n",
       " 'C_Z5_DECL_3M_RT',\n",
       " 'C_SAME_CHN_DECL_3M_RT',\n",
       " 'C_SAME_Z5_DECL_3M_RT',\n",
       " 'C_SAME_Z4_DECL_3M_RT',\n",
       " 'CM_DECL_CNT_3M_RT',\n",
       " 'C_P_APPR_DLR_3M_RT',\n",
       " 'C_SAME_STR_P_APP_3M_RT',\n",
       " 'C_P_NLR_3M_RT',\n",
       " 'C_G_APPR_DLR_3M_RT',\n",
       " 'C_SAME_STR_G_APP_3M_RT',\n",
       " 'C_PAID_G_CLM_CNT_3M_RT',\n",
       " 'C_T_APPR_CNT_3M_RT',\n",
       " 'C_T_APPR_DLR_3M_RT',\n",
       " 'C_MAX_T_FA_APPR_3M_RT',\n",
       " 'C_PAID_T_CLM_CNT_3M_RT',\n",
       " 'C_PAID_T_CLM_DLR_3M_RT',\n",
       " 'C_UNPD_T_CLM_CNT_3M_RT',\n",
       " 'C_UNPD_T_CLM_DLR_3M_RT',\n",
       " 'C_P_CLM_CNT_3M_RT',\n",
       " 'C_STD_P_F_AVG_FA_3M_RT',\n",
       " 'C_STD_G_F_AVG_FA_3M_RT',\n",
       " 'CM_STD_AVG_FA_3M_RT',\n",
       " 'C_PD_MAX_FA_3M_RT',\n",
       " 'C_D_MAX_P_FA_3M_RT',\n",
       " 'C_D_MAX_T_FA_3M_RT',\n",
       " 'CM_D_MAX_FA_3M_RT',\n",
       " 'CM_PD_MAX_AP_FA_3M_RT',\n",
       " 'C_FA_PD_AVG_3M_RT',\n",
       " 'C_R_STA_DECL_CNT_3M_RT',\n",
       " 'C_P_STN_APPR_3M_RT_IND',\n",
       " 'C_ATT_CNT_60D_RT',\n",
       " 'C_MAX_ATT_FA_60D_RT',\n",
       " 'C_STA_ATT_CNT_60D_RT',\n",
       " 'C_Z5_ATT_CNT_60D_RT',\n",
       " 'C_SAME_STR_ATT_60D_RT',\n",
       " 'C_SAME_Z5_ATT_60D_RT',\n",
       " 'CM_ATT_CNT_60D_RT',\n",
       " 'CM_MAX_ATT_FA_60D_RT',\n",
       " 'C_PAID_CLM_DLR_60D_RT',\n",
       " 'C_UNPD_CLM_DLR_60D_RT',\n",
       " 'C_NLR_60D_RT',\n",
       " 'C_STA_APPR_CNT_60D_RT',\n",
       " 'C_SAME_CHN_APPR_60D_RT',\n",
       " 'C_SAME_STR_APPR_60D_RT',\n",
       " 'C_SAME_Z4_APPR_60D_RT',\n",
       " 'C_SAME_Z3_APPR_60D_RT',\n",
       " 'CM_APPR_CNT_60D_RT',\n",
       " 'CM_MAX_APPR_FA_60D_RT',\n",
       " 'C_DECL_DLR_60D_EX_RT',\n",
       " 'C_G_APPR_DLR_60D_RT',\n",
       " 'C_MAX_G_FA_APPR_60D_RT',\n",
       " 'C_PAID_G_CLM_CNT_60D_RT',\n",
       " 'C_G_GLR_60D_RT',\n",
       " 'C_T_APPR_CNT_60D_RT',\n",
       " 'C_T_APPR_DLR_60D_RT',\n",
       " 'C_MAX_T_FA_APPR_60D_RT',\n",
       " 'C_PAID_T_CLM_DLR_60D_RT',\n",
       " 'C_UNPD_T_CLM_CNT_60D_RT',\n",
       " 'C_UNPD_T_CLM_DLR_60D_RT',\n",
       " 'C_T_NLR_60D_RT',\n",
       " 'C_STD_T_F_AVG_FA_60D_RT',\n",
       " 'CM_STD_AVG_AP_FA_60D_RT',\n",
       " 'CM_STD_AVG_FA_60D_RT',\n",
       " 'C_PD_MAX_FA_60D_RT',\n",
       " 'C_D_MAX_P_FA_60D_RT',\n",
       " 'C_UNIT_DECL_RATE_60D_RT',\n",
       " 'C_DLR_DECL_RATE_60D_RT',\n",
       " 'C_D_FA_AVG_60D_RT',\n",
       " 'C_P_STN_APPR_60D_RT_IND',\n",
       " 'C_MAX_ATT_FA_30D_RT',\n",
       " 'C_STA_ATT_CNT_30D_RT',\n",
       " 'C_SAME_CHN_ATT_30D_RT',\n",
       " 'C_SAME_Z4_ATT_30D_RT',\n",
       " 'CM_ATT_CNT_30D_RT',\n",
       " 'C_UNPD_CLM_DLR_30D_RT',\n",
       " 'C_SAME_CHN_APPR_30D_RT',\n",
       " 'C_SAME_STR_APPR_30D_RT',\n",
       " 'CM_MAX_APPR_FA_30D_RT',\n",
       " 'C_DECL_DLR_30D_EX_RT',\n",
       " 'C_Z5_DECL_30D_RT',\n",
       " 'C_SAME_CHN_DECL_30D_RT',\n",
       " 'C_SAME_Z4_DECL_30D_RT',\n",
       " 'CM_DECL_CNT_30D_RT',\n",
       " 'C_PAID_P_CLM_CNT_30D_RT',\n",
       " 'C_UNPD_P_CLM_CNT_30D_RT',\n",
       " 'C_P_GLR_30D_RT',\n",
       " 'C_PAID_G_CLM_CNT_30D_RT',\n",
       " 'C_T_APPR_CNT_30D_RT',\n",
       " 'C_PAID_T_CLM_DLR_30D_RT',\n",
       " 'C_CLM_DLR_30D_RT',\n",
       " 'C_P_CLM_CNT_30D_RT',\n",
       " 'C_STD_P_F_AVG_FA_30D_RT',\n",
       " 'C_STD_G_F_AVG_FA_30D_RT',\n",
       " 'CM_STD_AVG_AP_FA_30D_RT',\n",
       " 'CM_STD_AVG_FA_30D_RT',\n",
       " 'C_PD_MAX_G_FA_30D_RT',\n",
       " 'CM_D_MAX_FA_30D_RT',\n",
       " 'C_UNIT_DECL_RATE_30D_RT',\n",
       " 'C_DLR_DECL_RATE_30D_RT',\n",
       " 'C_P_STN_APPR_30D_RT_IND',\n",
       " 'C_G_STN_APPR_30D_RT_IND',\n",
       " 'C_STD_ATT_FA_21D_RT',\n",
       " 'C_SAME_STR_ATT_21D_RT',\n",
       " 'C_SAME_Z3_ATT_21D_RT',\n",
       " 'C_APPR_CNT_21D_RT',\n",
       " 'C_MAX_APPR_FA_21D_RT',\n",
       " 'C_UNPD_CLM_CNT_21D_RT',\n",
       " 'C_UNPD_CLM_DLR_21D_RT',\n",
       " 'C_GLR_21D_RT',\n",
       " 'C_SAME_STR_APPR_21D_RT',\n",
       " 'C_SAME_Z3_APPR_21D_RT',\n",
       " 'CM_APPR_CNT_21D_RT',\n",
       " 'CM_MAX_APPR_FA_21D_RT',\n",
       " 'C_DECL_CNT_21D_RT',\n",
       " 'C_DECL_CNT_21D_EX_RT',\n",
       " 'C_DECL_DLR_21D_RT',\n",
       " 'C_STR_CNT_DECL_SSN_21D_RT',\n",
       " 'C_Z5_DECL_21D_RT',\n",
       " 'C_SAME_CHN_DECL_21D_RT',\n",
       " 'C_SAME_STR_DECL_21D_RT',\n",
       " 'C_P_APPR_CNT_21D_RT',\n",
       " 'C_P_APPR_DLR_21D_RT',\n",
       " 'C_PAID_P_CLM_CNT_21D_RT',\n",
       " 'C_PAID_P_CLM_DLR_21D_RT',\n",
       " 'C_UNPD_P_CLM_CNT_21D_RT',\n",
       " 'C_MAX_G_FA_APPR_21D_RT',\n",
       " 'C_SAME_STR_G_APP_21D_RT',\n",
       " 'C_UNPD_G_CLM_DLR_21D_RT',\n",
       " 'C_G_GLR_21D_RT',\n",
       " 'C_G_NLR_21D_RT',\n",
       " 'C_PAID_T_CLM_CNT_21D_RT',\n",
       " 'C_UNPD_T_CLM_CNT_21D_RT',\n",
       " 'C_T_GLR_21D_RT',\n",
       " 'C_CLM_DLR_21D_RT',\n",
       " 'C_STD_F_AVG_FA_21D_RT',\n",
       " 'C_STD_G_F_AVG_FA_21D_RT',\n",
       " 'C_STD_T_F_AVG_FA_21D_RT',\n",
       " 'C_D_MAX_T_FA_21D_RT',\n",
       " 'CM_D_MAX_FA_21D_RT',\n",
       " 'CM_PD_MAX_AP_FA_21D_RT',\n",
       " 'C_UNIT_DECL_RATE_21D_RT',\n",
       " 'C_DLR_DECL_RATE_21D_RT',\n",
       " 'C_FA_PD_AVG_21D_RT',\n",
       " 'C_R_STA_DECL_CNT_21D_RT',\n",
       " 'C_P_STN_APPR_21D_RT_IND',\n",
       " 'C_STD_ATT_FA_18D_RT',\n",
       " 'C_SAME_CHN_ATT_18D_RT',\n",
       " 'C_SAME_Z4_ATT_18D_RT',\n",
       " 'C_SAME_Z3_ATT_18D_RT',\n",
       " 'CM_ATT_CNT_18D_RT',\n",
       " 'C_APPR_CNT_18D_RT',\n",
       " 'C_APPR_DLR_18D_RT',\n",
       " 'C_PAID_CLM_CNT_18D_RT',\n",
       " 'C_PAID_CLM_DLR_18D_RT',\n",
       " 'C_UNPD_CLM_CNT_18D_RT',\n",
       " 'C_UNPD_CLM_DLR_18D_RT',\n",
       " 'C_GLR_18D_RT',\n",
       " 'C_SAME_Z3_APPR_18D_RT',\n",
       " 'CM_MAX_APPR_FA_18D_RT',\n",
       " 'C_DECL_DLR_18D_RT',\n",
       " 'C_STR_CNT_DECL_SSN_18D_RT',\n",
       " 'C_SAME_CHN_DECL_18D_RT',\n",
       " 'C_SAME_Z5_DECL_18D_RT',\n",
       " 'C_SAME_STR_P_APP_18D_RT',\n",
       " 'C_P_GLR_18D_RT',\n",
       " 'C_P_NLR_18D_RT',\n",
       " 'C_G_APPR_DLR_18D_RT',\n",
       " 'C_PAID_G_CLM_CNT_18D_RT',\n",
       " 'C_UNPD_G_CLM_DLR_18D_RT',\n",
       " 'C_T_APPR_CNT_18D_RT',\n",
       " 'C_UNPD_T_CLM_DLR_18D_RT',\n",
       " 'C_T_GLR_18D_RT',\n",
       " 'C_CLM_DLR_18D_RT',\n",
       " 'C_P_CLM_CNT_18D_RT',\n",
       " 'C_STD_F_AVG_FA_18D_RT',\n",
       " 'C_STD_T_F_AVG_FA_18D_RT',\n",
       " 'CM_STD_AVG_AP_FA_18D_RT',\n",
       " 'C_D_MAX_P_FA_18D_RT',\n",
       " 'C_D_MAX_G_FA_18D_RT',\n",
       " 'CM_D_MAX_AP_FA_18D_RT',\n",
       " 'C_UNIT_DECL_RATE_18D_RT',\n",
       " 'C_D_FA_AVG_18D_RT',\n",
       " 'C_R_STA_DECL_CNT_18D_RT',\n",
       " 'C_T_STN_APPR_18D_RT_IND',\n",
       " 'C_MAX_ATT_FA_14D_RT',\n",
       " 'C_SAME_STR_ATT_14D_RT',\n",
       " 'CM_MAX_ATT_FA_14D_RT',\n",
       " 'C_APPR_CNT_14D_RT',\n",
       " 'C_UNPD_CLM_DLR_14D_RT',\n",
       " 'C_SAME_CHN_APPR_14D_RT',\n",
       " 'CM_APPR_CNT_14D_RT',\n",
       " 'CM_MAX_APPR_FA_14D_RT',\n",
       " 'C_DECL_CNT_14D_EX_RT',\n",
       " 'C_DECL_DLR_14D_RT',\n",
       " 'C_STR_CNT_DECL_SSN_14D_RT',\n",
       " 'C_SAME_CHN_DECL_14D_RT',\n",
       " 'C_SAME_Z5_DECL_14D_RT',\n",
       " 'C_SAME_Z4_DECL_14D_RT',\n",
       " 'C_P_APPR_DLR_14D_RT',\n",
       " 'C_MAX_P_FA_APPR_14D_RT',\n",
       " 'C_SAME_STR_P_APP_14D_RT',\n",
       " 'C_PAID_P_CLM_CNT_14D_RT',\n",
       " 'C_UNPD_P_CLM_CNT_14D_RT',\n",
       " 'C_PAID_G_CLM_CNT_14D_RT',\n",
       " 'C_G_GLR_14D_RT',\n",
       " 'C_T_APPR_CNT_14D_RT',\n",
       " 'C_T_APPR_DLR_14D_RT',\n",
       " 'C_PAID_T_CLM_CNT_14D_RT',\n",
       " 'C_T_NLR_14D_RT',\n",
       " 'CM_STD_AVG_AP_FA_14D_RT',\n",
       " 'C_D_MAX_FA_14D_RT',\n",
       " 'C_PD_MAX_FA_14D_RT',\n",
       " 'C_D_MAX_T_FA_14D_RT',\n",
       " 'CM_D_MAX_FA_14D_RT',\n",
       " 'CM_PD_MAX_FA_14D_RT',\n",
       " 'CM_PD_MAX_AP_FA_14D_RT',\n",
       " 'C_UNIT_DECL_RATE_14D_RT',\n",
       " 'C_D_FA_AVG_14D_RT',\n",
       " 'C_FA_PD_AVG_14D_RT',\n",
       " 'C_R_STA_DECL_CNT_14D_RT',\n",
       " 'C_G_STN_APPR_14D_RT_IND',\n",
       " 'C_ATT_CNT_7D_RT',\n",
       " 'C_ATT_DLR_7D_RT',\n",
       " 'C_STD_ATT_FA_7D_RT',\n",
       " 'C_MAX_ATT_FA_7D_RT',\n",
       " 'C_SAME_Z3_ATT_7D_RT',\n",
       " 'C_APPR_CNT_7D_RT',\n",
       " 'C_PAID_CLM_CNT_7D_RT',\n",
       " 'C_NLR_7D_RT',\n",
       " 'C_STA_APPR_CNT_7D_RT',\n",
       " 'C_SAME_STR_APPR_7D_RT',\n",
       " 'C_SAME_Z4_APPR_7D_RT',\n",
       " 'CM_MAX_APPR_FA_7D_RT',\n",
       " 'C_DECL_CNT_7D_EX_RT',\n",
       " 'C_CHN_DECL_CNT_7D_RT',\n",
       " 'C_SAME_CHN_DECL_7D_RT',\n",
       " 'C_SAME_Z3_DECL_7D_RT',\n",
       " 'C_P_APPR_DLR_7D_RT',\n",
       " 'C_MAX_P_FA_APPR_7D_RT',\n",
       " 'C_PAID_P_CLM_CNT_7D_RT',\n",
       " 'C_UNPD_P_CLM_DLR_7D_RT',\n",
       " 'C_P_GLR_7D_RT',\n",
       " 'C_P_NLR_7D_RT',\n",
       " 'C_G_APPR_DLR_7D_RT',\n",
       " 'C_PAID_G_CLM_DLR_7D_RT',\n",
       " 'C_G_GLR_7D_RT',\n",
       " 'C_G_NLR_7D_RT',\n",
       " 'C_SAME_STR_T_APP_7D_RT',\n",
       " 'C_T_GLR_7D_RT',\n",
       " 'C_T_NLR_7D_RT',\n",
       " 'C_CLM_DLR_7D_RT',\n",
       " 'CM_STD_AVG_FA_7D_RT',\n",
       " 'C_PD_MAX_G_FA_7D_RT',\n",
       " 'C_D_MAX_T_FA_7D_RT',\n",
       " 'C_PD_MAX_T_FA_7D_RT',\n",
       " 'CM_PD_MAX_FA_7D_RT',\n",
       " 'CM_PD_MAX_AP_FA_7D_RT',\n",
       " 'C_DLR_DECL_RATE_7D_RT',\n",
       " 'C_R_STA_DECL_CNT_7D_RT',\n",
       " 'C_T_STN_APPR_7D_RT_IND',\n",
       " 'C_MAX_ATT_FA_3D_RT',\n",
       " 'C_SAME_Z5_ATT_3D_RT',\n",
       " 'C_PAID_CLM_CNT_3D_RT',\n",
       " 'C_UNPD_CLM_DLR_3D_RT',\n",
       " 'C_GLR_3D_RT',\n",
       " 'C_NLR_3D_RT',\n",
       " 'C_STA_APPR_CNT_3D_RT',\n",
       " 'C_SAME_CHN_APPR_3D_RT',\n",
       " 'C_SAME_STR_APPR_3D_RT',\n",
       " 'C_SAME_Z4_APPR_3D_RT',\n",
       " 'CM_APPR_CNT_3D_RT',\n",
       " 'C_DECL_CNT_3D_EX_RT',\n",
       " 'C_CHN_DECL_CNT_3D_RT',\n",
       " 'C_Z5_DECL_3D_RT',\n",
       " 'C_SAME_CHN_DECL_3D_RT',\n",
       " 'C_SAME_STR_DECL_3D_RT',\n",
       " 'C_SAME_Z4_DECL_3D_RT',\n",
       " 'C_SAME_Z3_DECL_3D_RT',\n",
       " 'C_G_APPR_DLR_3D_RT',\n",
       " 'C_UNPD_G_CLM_DLR_3D_RT',\n",
       " 'C_MAX_T_FA_APPR_3D_RT',\n",
       " 'C_T_GLR_3D_RT',\n",
       " 'C_T_NLR_3D_RT',\n",
       " 'C_P_CLM_CNT_3D_RT',\n",
       " 'C_STD_F_AVG_FA_3D_RT',\n",
       " 'C_STD_P_F_AVG_FA_3D_RT',\n",
       " 'C_STD_G_F_AVG_FA_3D_RT',\n",
       " 'C_D_MAX_G_FA_3D_RT',\n",
       " 'C_PD_MAX_G_FA_3D_RT',\n",
       " 'C_R_STA_DECL_CNT_3D_RT',\n",
       " 'C_Z5_ATT_CNT_1D_RT',\n",
       " 'C_SAME_Z5_ATT_1D_RT',\n",
       " 'CM_ATT_CNT_1D_RT',\n",
       " 'C_STD_APPR_FA_1D_RT',\n",
       " 'C_PAID_CLM_CNT_1D_RT',\n",
       " 'C_PAID_CLM_DLR_1D_RT',\n",
       " 'C_UNPD_CLM_DLR_1D_RT',\n",
       " 'C_Z5_APPR_CNT_1D_RT',\n",
       " 'C_SAME_CHN_APPR_1D_RT',\n",
       " 'C_SAME_Z4_APPR_1D_RT',\n",
       " 'C_SAME_Z3_APPR_1D_RT',\n",
       " 'C_DECL_DLR_1D_RT',\n",
       " 'C_DECL_DLR_1D_EX_RT',\n",
       " 'C_CHN_DECL_CNT_1D_RT',\n",
       " 'C_Z5_DECL_1D_RT',\n",
       " 'C_SAME_STR_DECL_1D_RT',\n",
       " 'C_SAME_Z4_DECL_1D_RT',\n",
       " 'C_SAME_Z3_DECL_1D_RT',\n",
       " 'CM_DECL_CNT_1D_RT',\n",
       " 'C_P_APPR_DLR_1D_RT',\n",
       " 'C_MAX_P_FA_APPR_1D_RT',\n",
       " 'C_SAME_STR_P_APP_1D_RT',\n",
       " 'C_P_GLR_1D_RT',\n",
       " 'C_P_NLR_1D_RT',\n",
       " 'C_G_APPR_DLR_1D_RT',\n",
       " 'C_PAID_G_CLM_DLR_1D_RT',\n",
       " 'C_UNPD_G_CLM_CNT_1D_RT',\n",
       " 'C_G_NLR_1D_RT',\n",
       " 'C_PAID_T_CLM_CNT_1D_RT',\n",
       " 'C_PAID_T_CLM_DLR_1D_RT',\n",
       " 'C_T_GLR_1D_RT',\n",
       " 'C_STD_F_AVG_FA_1D_RT',\n",
       " 'CM_STD_AVG_FA_1D_RT',\n",
       " 'C_PD_MAX_FA_1D_RT',\n",
       " 'C_D_MAX_P_FA_1D_RT',\n",
       " 'C_D_MAX_G_FA_1D_RT',\n",
       " 'C_PD_MAX_G_FA_1D_RT',\n",
       " 'C_PD_MAX_T_FA_1D_RT',\n",
       " 'CM_D_MAX_FA_1D_RT',\n",
       " 'CM_PD_MAX_FA_1D_RT',\n",
       " 'CM_PD_MAX_AP_FA_1D_RT',\n",
       " 'C_UNIT_DECL_RATE_1D_RT',\n",
       " 'C_D_FA_AVG_1D_RT',\n",
       " 'C_FA_PD_AVG_1D_RT',\n",
       " 'C_R_STA_DECL_CNT_1D_RT',\n",
       " 'C_P_STN_APPR_1D_RT_IND',\n",
       " 'C_G_STN_APPR_1D_RT_IND',\n",
       " 'C_ATT_CNT_7D_L1',\n",
       " 'C_APPR_CNT_6M_L14',\n",
       " 'C_APPR_CNT_6M_L7',\n",
       " 'C_APPR_CNT_3M_L14',\n",
       " 'C_APPR_CNT_3M_L7',\n",
       " 'C_APPR_CNT_30D_L14',\n",
       " 'C_APPR_CNT_30D_L7',\n",
       " 'CM_APPR_CNT_24M_L1',\n",
       " 'CM_APPR_CNT_12M_L14',\n",
       " 'CM_APPR_CNT_12M_L7',\n",
       " 'CM_APPR_CNT_12M_L1',\n",
       " 'CM_APPR_CNT_6M_L1',\n",
       " 'CM_APPR_CNT_3M_L7',\n",
       " 'C_APPR_DLR_6M_L7',\n",
       " 'C_SAME_Z4_APPR_24M_L7',\n",
       " 'C_SAME_CHN_APPR_24M_L7',\n",
       " 'C_SAME_Z5_APPR_12M_L14',\n",
       " 'C_SAME_Z5_APPR_12M_L7',\n",
       " 'C_SAME_CHN_APPR_12M_L7',\n",
       " 'C_SAME_STR_APPR_6M_L14',\n",
       " 'C_SAME_Z5_APPR_6M_L14',\n",
       " 'C_SAME_Z3_APPR_6M_L14',\n",
       " 'C_SAME_Z3_APPR_6M_L7',\n",
       " 'C_SAME_CHN_APPR_6M_L14',\n",
       " 'C_SAME_CHN_APPR_6M_L7',\n",
       " 'C_SAME_Z5_APPR_3M_L14',\n",
       " 'C_SAME_Z4_APPR_3M_L14',\n",
       " 'C_SAME_Z3_APPR_3M_L7',\n",
       " 'C_R_AV_APP_D_12M_14D_RT',\n",
       " 'C_R_AV_APP_D_6M_7D_RT',\n",
       " 'C_R_DLY_APPR_24M_14D_RT',\n",
       " 'C_R_DLY_APPR_12M_14D_RT',\n",
       " 'C_R_DLY_APPR_6M_3M_RT',\n",
       " 'C_STD_C_AVG_TIME_24M_RT',\n",
       " 'C_STD_C_AVG_TIME_6M_RT',\n",
       " 'C_STD_C_AVG_TIME_30D_RT',\n",
       " 'C_STD_C_AVG_TIME_18D_RT',\n",
       " 'C_STD_C_AVG_TIME_14D_RT']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to replace missing values, different logic for numeric vs categoricals\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train.columns if \n",
    "                X_train[cname].dtype in ['int64', 'float64']]\n",
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FACE_AMOUNT</th>\n",
       "      <th>LOCAL_HOUR</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MOD_FACE_AMT</th>\n",
       "      <th>FA_ROUND</th>\n",
       "      <th>M_DAYS_FIRST_DECL_L1</th>\n",
       "      <th>M_ATT_CNT_60D_L1</th>\n",
       "      <th>M_ATT_CNT_90D_L1</th>\n",
       "      <th>M_ATT_DLR_3D_L1</th>\n",
       "      <th>M_ATT_DLR_30D_L1</th>\n",
       "      <th>...</th>\n",
       "      <th>C_R_AV_APP_D_12M_14D_RT</th>\n",
       "      <th>C_R_AV_APP_D_6M_7D_RT</th>\n",
       "      <th>C_R_DLY_APPR_24M_14D_RT</th>\n",
       "      <th>C_R_DLY_APPR_12M_14D_RT</th>\n",
       "      <th>C_R_DLY_APPR_6M_3M_RT</th>\n",
       "      <th>C_STD_C_AVG_TIME_24M_RT</th>\n",
       "      <th>C_STD_C_AVG_TIME_6M_RT</th>\n",
       "      <th>C_STD_C_AVG_TIME_30D_RT</th>\n",
       "      <th>C_STD_C_AVG_TIME_18D_RT</th>\n",
       "      <th>C_STD_C_AVG_TIME_14D_RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>353.46</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>494.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.409524</td>\n",
       "      <td>1.671429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.197902</td>\n",
       "      <td>1.044647</td>\n",
       "      <td>-11.425616</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>666.44</td>\n",
       "      <td>7.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3980.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.045714</td>\n",
       "      <td>1.319549</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>-2.133350</td>\n",
       "      <td>-1.849258</td>\n",
       "      <td>-1.862653</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>418.91</td>\n",
       "      <td>7.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2048.91</td>\n",
       "      <td>...</td>\n",
       "      <td>1.040836</td>\n",
       "      <td>1.046245</td>\n",
       "      <td>1.420635</td>\n",
       "      <td>1.166113</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>-3.392236</td>\n",
       "      <td>-3.746517</td>\n",
       "      <td>-43.276650</td>\n",
       "      <td>-478.360659</td>\n",
       "      <td>-478.360659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>636.81</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>995.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-2.001617</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>768.07</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14108.02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.613987</td>\n",
       "      <td>1.448185</td>\n",
       "      <td>4.649351</td>\n",
       "      <td>7.163265</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-1.472374</td>\n",
       "      <td>-0.623174</td>\n",
       "      <td>2.810837</td>\n",
       "      <td>2.345354</td>\n",
       "      <td>2.345354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 605 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FACE_AMOUNT  LOCAL_HOUR   AGE  MOD_FACE_AMT  FA_ROUND  \\\n",
       "0       353.46         7.0  20.0          53.0       0.0   \n",
       "1       666.44         7.0  45.0          66.0       0.0   \n",
       "2       418.91         7.0  61.0          19.0       0.0   \n",
       "3       636.81         7.0  43.0          37.0       0.0   \n",
       "4       768.07         7.0  41.0          68.0       0.0   \n",
       "\n",
       "   M_DAYS_FIRST_DECL_L1  M_ATT_CNT_60D_L1  M_ATT_CNT_90D_L1  M_ATT_DLR_3D_L1  \\\n",
       "0                -999.0               6.0              12.0              0.0   \n",
       "1                  81.0              21.0              31.0              0.0   \n",
       "2                -999.0              12.0              19.0              0.0   \n",
       "3                -999.0               5.0               7.0              0.0   \n",
       "4                  77.0              57.0              91.0              0.0   \n",
       "\n",
       "   M_ATT_DLR_30D_L1  ...  C_R_AV_APP_D_12M_14D_RT  C_R_AV_APP_D_6M_7D_RT  \\\n",
       "0            494.44  ...                 0.773816               0.000000   \n",
       "1           3980.25  ...                 0.897903               0.000000   \n",
       "2           2048.91  ...                 1.040836               1.046245   \n",
       "3            995.30  ...                 0.000000            -999.000000   \n",
       "4          14108.02  ...                 1.613987               1.448185   \n",
       "\n",
       "   C_R_DLY_APPR_24M_14D_RT  C_R_DLY_APPR_12M_14D_RT  C_R_DLY_APPR_6M_3M_RT  \\\n",
       "0                 3.409524                 1.671429               0.857143   \n",
       "1                 2.045714                 1.319549               0.857143   \n",
       "2                 1.420635                 1.166113               0.785714   \n",
       "3                 0.000000                 0.000000            -999.000000   \n",
       "4                 4.649351                 7.163265            -999.000000   \n",
       "\n",
       "   C_STD_C_AVG_TIME_24M_RT  C_STD_C_AVG_TIME_6M_RT  C_STD_C_AVG_TIME_30D_RT  \\\n",
       "0                 1.197902                1.044647               -11.425616   \n",
       "1                -2.133350               -1.849258                -1.862653   \n",
       "2                -3.392236               -3.746517               -43.276650   \n",
       "3                -2.001617             -999.000000              -999.000000   \n",
       "4                -1.472374               -0.623174                 2.810837   \n",
       "\n",
       "   C_STD_C_AVG_TIME_18D_RT  C_STD_C_AVG_TIME_14D_RT  \n",
       "0              -999.000000              -999.000000  \n",
       "1              -999.000000              -999.000000  \n",
       "2              -478.360659              -478.360659  \n",
       "3              -999.000000              -999.000000  \n",
       "4                 2.345354                 2.345354  \n",
       "\n",
       "[5 rows x 605 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute numeric columns, simple fill with -999 value\n",
    "my_numeric_imputer = SimpleImputer(strategy='constant', fill_value=-999)\n",
    "num_X_train = X_train[numerical_cols]\n",
    "num_X_val = X_val[numerical_cols]\n",
    "num_X_deep_dive = X_deep_dive[numerical_cols]\n",
    "\n",
    "imputed_num_X_train = pd.DataFrame(my_numeric_imputer.fit_transform(num_X_train))\n",
    "imputed_num_X_val = pd.DataFrame(my_numeric_imputer.transform(num_X_val))\n",
    "imputed_num_X_deep_dive = pd.DataFrame(my_numeric_imputer.transform(num_X_deep_dive))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_num_X_train.columns = num_X_train.columns\n",
    "imputed_num_X_val.columns = num_X_val.columns\n",
    "imputed_num_X_deep_dive.columns = num_X_deep_dive.columns\n",
    "\n",
    "imputed_num_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NAT_POSITIVE_GRADE', 'ID_STATION_STATE', 'DAY_OF_WEEK', 'ASIGN']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect categorical columns prior imputation\n",
    "categorical_cols = [cname for cname in X_train.columns if\n",
    "                    X_train[cname].nunique() < 21 and \n",
    "                    X_train[cname].dtype == \"object\"]\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAT_POSITIVE_GRADE</th>\n",
       "      <th>ID_STATION_STATE</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>ASIGN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>FRI</td>\n",
       "      <td>VIRGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>FRI</td>\n",
       "      <td>CAPRICORN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>FRI</td>\n",
       "      <td>ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Z</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>FRI</td>\n",
       "      <td>PISCES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>FRI</td>\n",
       "      <td>AQUARIUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>FRI</td>\n",
       "      <td>SCORPIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>FRI</td>\n",
       "      <td>SAGITTARIUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>H</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>FRI</td>\n",
       "      <td>CANCER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>C</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>FRI</td>\n",
       "      <td>CANCER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Z</td>\n",
       "      <td>MIS-MATCH</td>\n",
       "      <td>FRI</td>\n",
       "      <td>SCORPIO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NAT_POSITIVE_GRADE ID_STATION_STATE DAY_OF_WEEK        ASIGN\n",
       "0                  H            MATCH         FRI        VIRGO\n",
       "1                  C            MATCH         FRI    CAPRICORN\n",
       "2                  C            MATCH         FRI        ARIES\n",
       "3                  Z            MATCH         FRI       PISCES\n",
       "4                  H            MATCH         FRI     AQUARIUS\n",
       "5                  C            MATCH         FRI      SCORPIO\n",
       "6                  M            MATCH         FRI  SAGITTARIUS\n",
       "7                  H            MATCH         FRI       CANCER\n",
       "8                  C            MATCH         FRI       CANCER\n",
       "9                  Z        MIS-MATCH         FRI      SCORPIO"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Impute character values\n",
    "my_categorical_imputer = SimpleImputer(strategy='constant', fill_value='Z')\n",
    "char_X_train = X_train[categorical_cols]\n",
    "char_X_val = X_val[categorical_cols]\n",
    "char_X_deep_dive = X_deep_dive[categorical_cols]\n",
    "\n",
    "imputed_char_X_train = pd.DataFrame(my_categorical_imputer.fit_transform(char_X_train))\n",
    "imputed_char_X_val = pd.DataFrame(my_categorical_imputer.transform(char_X_val))\n",
    "imputed_char_X_deep_dive = pd.DataFrame(my_categorical_imputer.transform(char_X_deep_dive))\n",
    "\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_char_X_train.columns = char_X_train.columns\n",
    "imputed_char_X_val.columns = char_X_val.columns\n",
    "imputed_char_X_deep_dive.columns = char_X_deep_dive.columns\n",
    "\n",
    "imputed_char_X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I need to purge the columns that take on only one value\n",
    "single_val_cat_cols = [cname for cname in imputed_char_X_train.columns if\n",
    "                    imputed_char_X_train[cname].nunique() < 2]\n",
    "single_val_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAT_POSITIVE_GRADE_C</th>\n",
       "      <th>NAT_POSITIVE_GRADE_F</th>\n",
       "      <th>NAT_POSITIVE_GRADE_H</th>\n",
       "      <th>NAT_POSITIVE_GRADE_M</th>\n",
       "      <th>NAT_POSITIVE_GRADE_Q</th>\n",
       "      <th>NAT_POSITIVE_GRADE_T</th>\n",
       "      <th>NAT_POSITIVE_GRADE_W</th>\n",
       "      <th>NAT_POSITIVE_GRADE_Z</th>\n",
       "      <th>NAT_POSITIVE_GRADE_\\</th>\n",
       "      <th>NAT_POSITIVE_GRADE_^</th>\n",
       "      <th>...</th>\n",
       "      <th>ASIGN_CAPRICORN</th>\n",
       "      <th>ASIGN_GEMINI</th>\n",
       "      <th>ASIGN_LEO</th>\n",
       "      <th>ASIGN_LIBRA</th>\n",
       "      <th>ASIGN_PISCES</th>\n",
       "      <th>ASIGN_SAGITTARIUS</th>\n",
       "      <th>ASIGN_SCORPIO</th>\n",
       "      <th>ASIGN_TAURUS</th>\n",
       "      <th>ASIGN_VIRGO</th>\n",
       "      <th>ASIGN_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125405 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        NAT_POSITIVE_GRADE_C  NAT_POSITIVE_GRADE_F  NAT_POSITIVE_GRADE_H  \\\n",
       "0                        0.0                   0.0                   1.0   \n",
       "1                        1.0                   0.0                   0.0   \n",
       "2                        1.0                   0.0                   0.0   \n",
       "3                        0.0                   0.0                   0.0   \n",
       "4                        0.0                   0.0                   1.0   \n",
       "...                      ...                   ...                   ...   \n",
       "125400                   0.0                   0.0                   0.0   \n",
       "125401                   1.0                   0.0                   0.0   \n",
       "125402                   0.0                   0.0                   1.0   \n",
       "125403                   0.0                   0.0                   1.0   \n",
       "125404                   0.0                   0.0                   0.0   \n",
       "\n",
       "        NAT_POSITIVE_GRADE_M  NAT_POSITIVE_GRADE_Q  NAT_POSITIVE_GRADE_T  \\\n",
       "0                        0.0                   0.0                   0.0   \n",
       "1                        0.0                   0.0                   0.0   \n",
       "2                        0.0                   0.0                   0.0   \n",
       "3                        0.0                   0.0                   0.0   \n",
       "4                        0.0                   0.0                   0.0   \n",
       "...                      ...                   ...                   ...   \n",
       "125400                   0.0                   0.0                   0.0   \n",
       "125401                   0.0                   0.0                   0.0   \n",
       "125402                   0.0                   0.0                   0.0   \n",
       "125403                   0.0                   0.0                   0.0   \n",
       "125404                   0.0                   0.0                   0.0   \n",
       "\n",
       "        NAT_POSITIVE_GRADE_W  NAT_POSITIVE_GRADE_Z  NAT_POSITIVE_GRADE_\\  \\\n",
       "0                        0.0                   0.0                   0.0   \n",
       "1                        0.0                   0.0                   0.0   \n",
       "2                        0.0                   0.0                   0.0   \n",
       "3                        0.0                   1.0                   0.0   \n",
       "4                        0.0                   0.0                   0.0   \n",
       "...                      ...                   ...                   ...   \n",
       "125400                   0.0                   1.0                   0.0   \n",
       "125401                   0.0                   0.0                   0.0   \n",
       "125402                   0.0                   0.0                   0.0   \n",
       "125403                   0.0                   0.0                   0.0   \n",
       "125404                   0.0                   1.0                   0.0   \n",
       "\n",
       "        NAT_POSITIVE_GRADE_^  ...  ASIGN_CAPRICORN  ASIGN_GEMINI  ASIGN_LEO  \\\n",
       "0                        0.0  ...              0.0           0.0        0.0   \n",
       "1                        0.0  ...              1.0           0.0        0.0   \n",
       "2                        0.0  ...              0.0           0.0        0.0   \n",
       "3                        0.0  ...              0.0           0.0        0.0   \n",
       "4                        0.0  ...              0.0           0.0        0.0   \n",
       "...                      ...  ...              ...           ...        ...   \n",
       "125400                   0.0  ...              0.0           0.0        0.0   \n",
       "125401                   0.0  ...              0.0           0.0        0.0   \n",
       "125402                   0.0  ...              0.0           0.0        0.0   \n",
       "125403                   0.0  ...              0.0           1.0        0.0   \n",
       "125404                   0.0  ...              0.0           0.0        0.0   \n",
       "\n",
       "        ASIGN_LIBRA  ASIGN_PISCES  ASIGN_SAGITTARIUS  ASIGN_SCORPIO  \\\n",
       "0               0.0           0.0                0.0            0.0   \n",
       "1               0.0           0.0                0.0            0.0   \n",
       "2               0.0           0.0                0.0            0.0   \n",
       "3               0.0           1.0                0.0            0.0   \n",
       "4               0.0           0.0                0.0            0.0   \n",
       "...             ...           ...                ...            ...   \n",
       "125400          0.0           0.0                0.0            0.0   \n",
       "125401          0.0           0.0                0.0            0.0   \n",
       "125402          0.0           0.0                0.0            0.0   \n",
       "125403          0.0           0.0                0.0            0.0   \n",
       "125404          0.0           0.0                0.0            0.0   \n",
       "\n",
       "        ASIGN_TAURUS  ASIGN_VIRGO  ASIGN_Z  \n",
       "0                0.0          1.0      0.0  \n",
       "1                0.0          0.0      0.0  \n",
       "2                0.0          0.0      0.0  \n",
       "3                0.0          0.0      0.0  \n",
       "4                0.0          0.0      0.0  \n",
       "...              ...          ...      ...  \n",
       "125400           0.0          0.0      0.0  \n",
       "125401           0.0          1.0      0.0  \n",
       "125402           1.0          0.0      0.0  \n",
       "125403           0.0          0.0      0.0  \n",
       "125404           1.0          0.0      0.0  \n",
       "\n",
       "[125405 rows x 33 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now I need to convert the categorical columms to binary indicators with one-hot encoder\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_imputed_char_X_train = pd.DataFrame(OH_encoder.fit_transform(imputed_char_X_train))\n",
    "OH_cols_imputed_char_X_val = pd.DataFrame(OH_encoder.transform(imputed_char_X_val))\n",
    "OH_cols_imputed_char_X_deep_dive = pd.DataFrame(OH_encoder.transform(imputed_char_X_deep_dive))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_imputed_char_X_train.index = imputed_char_X_train.index\n",
    "OH_cols_imputed_char_X_val.index = imputed_char_X_val.index\n",
    "OH_cols_imputed_char_X_deep_dive.index = imputed_char_X_deep_dive.index\n",
    "\n",
    "#and need to bring in the column names \n",
    "OH_cols_imputed_char_X_train.columns = OH_encoder.get_feature_names(list(imputed_char_X_train.columns))\n",
    "OH_cols_imputed_char_X_val.columns = OH_encoder.get_feature_names(list(imputed_char_X_val.columns))\n",
    "OH_cols_imputed_char_X_deep_dive.columns = OH_encoder.get_feature_names(list(imputed_char_X_deep_dive.columns))\n",
    "\n",
    "OH_cols_imputed_char_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the numeric features -- maybe later\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FACE_AMOUNT</th>\n",
       "      <th>LOCAL_HOUR</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MOD_FACE_AMT</th>\n",
       "      <th>FA_ROUND</th>\n",
       "      <th>M_DAYS_FIRST_DECL_L1</th>\n",
       "      <th>M_ATT_CNT_60D_L1</th>\n",
       "      <th>M_ATT_CNT_90D_L1</th>\n",
       "      <th>M_ATT_DLR_3D_L1</th>\n",
       "      <th>M_ATT_DLR_30D_L1</th>\n",
       "      <th>...</th>\n",
       "      <th>ASIGN_CAPRICORN</th>\n",
       "      <th>ASIGN_GEMINI</th>\n",
       "      <th>ASIGN_LEO</th>\n",
       "      <th>ASIGN_LIBRA</th>\n",
       "      <th>ASIGN_PISCES</th>\n",
       "      <th>ASIGN_SAGITTARIUS</th>\n",
       "      <th>ASIGN_SCORPIO</th>\n",
       "      <th>ASIGN_TAURUS</th>\n",
       "      <th>ASIGN_VIRGO</th>\n",
       "      <th>ASIGN_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>353.46</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>494.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>666.44</td>\n",
       "      <td>7.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3980.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>418.91</td>\n",
       "      <td>7.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2048.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>636.81</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>995.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>768.07</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14108.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 638 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FACE_AMOUNT  LOCAL_HOUR   AGE  MOD_FACE_AMT  FA_ROUND  \\\n",
       "0       353.46         7.0  20.0          53.0       0.0   \n",
       "1       666.44         7.0  45.0          66.0       0.0   \n",
       "2       418.91         7.0  61.0          19.0       0.0   \n",
       "3       636.81         7.0  43.0          37.0       0.0   \n",
       "4       768.07         7.0  41.0          68.0       0.0   \n",
       "\n",
       "   M_DAYS_FIRST_DECL_L1  M_ATT_CNT_60D_L1  M_ATT_CNT_90D_L1  M_ATT_DLR_3D_L1  \\\n",
       "0                -999.0               6.0              12.0              0.0   \n",
       "1                  81.0              21.0              31.0              0.0   \n",
       "2                -999.0              12.0              19.0              0.0   \n",
       "3                -999.0               5.0               7.0              0.0   \n",
       "4                  77.0              57.0              91.0              0.0   \n",
       "\n",
       "   M_ATT_DLR_30D_L1  ...  ASIGN_CAPRICORN  ASIGN_GEMINI  ASIGN_LEO  \\\n",
       "0            494.44  ...              0.0           0.0        0.0   \n",
       "1           3980.25  ...              1.0           0.0        0.0   \n",
       "2           2048.91  ...              0.0           0.0        0.0   \n",
       "3            995.30  ...              0.0           0.0        0.0   \n",
       "4          14108.02  ...              0.0           0.0        0.0   \n",
       "\n",
       "   ASIGN_LIBRA  ASIGN_PISCES  ASIGN_SAGITTARIUS  ASIGN_SCORPIO  ASIGN_TAURUS  \\\n",
       "0          0.0           0.0                0.0            0.0           0.0   \n",
       "1          0.0           0.0                0.0            0.0           0.0   \n",
       "2          0.0           0.0                0.0            0.0           0.0   \n",
       "3          0.0           1.0                0.0            0.0           0.0   \n",
       "4          0.0           0.0                0.0            0.0           0.0   \n",
       "\n",
       "   ASIGN_VIRGO  ASIGN_Z  \n",
       "0          1.0      0.0  \n",
       "1          0.0      0.0  \n",
       "2          0.0      0.0  \n",
       "3          0.0      0.0  \n",
       "4          0.0      0.0  \n",
       "\n",
       "[5 rows x 638 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now merge the categorical and numeric columns back together\n",
    "imputed_X_train = pd.concat([imputed_num_X_train, OH_cols_imputed_char_X_train], axis=1)\n",
    "imputed_X_val = pd.concat([imputed_num_X_val, OH_cols_imputed_char_X_val], axis=1)\n",
    "imputed_X_deep_dive = pd.concat([imputed_num_X_deep_dive, OH_cols_imputed_char_X_deep_dive], axis=1)\n",
    "\n",
    "imputed_X_deep_dive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FACE_AMOUNT',\n",
       " 'LOCAL_HOUR',\n",
       " 'AGE',\n",
       " 'MOD_FACE_AMT',\n",
       " 'FA_ROUND',\n",
       " 'M_DAYS_FIRST_DECL_L1',\n",
       " 'M_ATT_CNT_60D_L1',\n",
       " 'M_ATT_CNT_90D_L1',\n",
       " 'M_ATT_DLR_3D_L1',\n",
       " 'M_ATT_DLR_30D_L1',\n",
       " 'M_ATT_DLR_60D_L1',\n",
       " 'M_ATT_DLR_90D_L1',\n",
       " 'M_APPR_CNT_7D_L1',\n",
       " 'M_APPR_CNT_30D_L1',\n",
       " 'M_APPR_DLR_60D_L1',\n",
       " 'M_DECL_CNT_3D_L1',\n",
       " 'M_DECL_CNT_7D_L1',\n",
       " 'M_DECL_CNT_90D_L1',\n",
       " 'M_DECL_DLR_30D_L1',\n",
       " 'M_DECL_DLR_60D_L1',\n",
       " 'M_UNIT_GLR_60D_L1',\n",
       " 'M_UNIT_GLR_30D_L1',\n",
       " 'M_DLR_GLR_60D_L1',\n",
       " 'M_APPR_DLR_90D_L3',\n",
       " 'M_APPR_CNT_60D_L3',\n",
       " 'M_APPR_DLR_60D_L3',\n",
       " 'M_APPR_CNT_60D_L7',\n",
       " 'M_APP_CKNO_SFA_X_90D_L1',\n",
       " 'M_DECL_RATE_90D_L1',\n",
       " 'M_FA_DFAV_APPR_90D_L1',\n",
       " 'M_FA_DFMX_APPR_90D_L1',\n",
       " 'M_APPR_FA_SFA_60D_L1',\n",
       " 'M_APPR_CKNO_SFA_60D_L1',\n",
       " 'M_FA_DFAV_APPR_60D_L1',\n",
       " 'M_APP_CKNO_SFA_X_30D_L1',\n",
       " 'M_FA_DFAV_APPR_30D_L1',\n",
       " 'M_FA_PDFAV_APPR_30D_L1',\n",
       " 'M_APPR_FA_SFA_7D_L1',\n",
       " 'M_APP_CKNO_SFA_X_7D_L1',\n",
       " 'M_FA_PDFMX_APPR_7D_L1',\n",
       " 'M_APPR_FA_SFA_3D_L1',\n",
       " 'M_DECL_DLR_RATE_3D_L1',\n",
       " 'M_FA_DFAV_APPR_3D_L1',\n",
       " 'M_FA_PDFAV_APPR_3D_L1',\n",
       " 'M_FA_PDFMX_APPR_3D_L1',\n",
       " 'M_APPR_FA_SFA_1D_L1',\n",
       " 'M_FA_PDFAV_APPR_1D_L1',\n",
       " 'CM_CHKNO_INCR_TRM_RT',\n",
       " 'C_MIN_LAST_APPR_RT',\n",
       " 'C_DAY_LAST_APPR_RT',\n",
       " 'C_DAY_FIRST_APPR_RT',\n",
       " 'C_MIN_FIRST_DECL_RT',\n",
       " 'C_MIN_HIGHRISK_DECL_RT',\n",
       " 'C_MIN_LAST_P_APPR_RT',\n",
       " 'C_DAY_LAST_P_APPR_RT',\n",
       " 'C_DAY_FIRST_P_APPR_RT',\n",
       " 'C_MIN_LAST_G_APPR_RT',\n",
       " 'C_MIN_FIRST_G_APPR_RT',\n",
       " 'C_DAY_FIRST_G_APPR_RT',\n",
       " 'CM_MIN_FIRST_APPR_RT',\n",
       " 'C_ATT_CNT_24M_RT',\n",
       " 'C_MAX_ATT_FA_24M_RT',\n",
       " 'C_SAME_Z4_ATT_24M_RT',\n",
       " 'CM_MAX_ATT_FA_24M_RT',\n",
       " 'C_APPR_DLR_24M_RT',\n",
       " 'C_MAX_APPR_FA_24M_RT',\n",
       " 'C_UNPD_CLM_DLR_24M_RT',\n",
       " 'C_NLR_24M_RT',\n",
       " 'C_STA_APPR_CNT_24M_RT',\n",
       " 'C_Z5_APPR_CNT_24M_RT',\n",
       " 'C_SAME_Z4_APPR_24M_RT',\n",
       " 'C_SAME_Z3_APPR_24M_RT',\n",
       " 'C_DECL_DLR_24M_RT',\n",
       " 'C_DECL_DLR_24M_EX_RT',\n",
       " 'C_Z5_DECL_24M_RT',\n",
       " 'C_SAME_STR_DECL_24M_RT',\n",
       " 'C_SAME_Z5_DECL_24M_RT',\n",
       " 'C_SAME_Z3_DECL_24M_RT',\n",
       " 'CM_DECL_CNT_24M_RT',\n",
       " 'C_P_APPR_DLR_24M_RT',\n",
       " 'C_SAME_STR_P_APP_24M_RT',\n",
       " 'C_PAID_P_CLM_CNT_24M_RT',\n",
       " 'C_P_NLR_24M_RT',\n",
       " 'C_G_GLR_24M_RT',\n",
       " 'C_MAX_T_FA_APPR_24M_RT',\n",
       " 'C_STD_F_AVG_FA_24M_RT',\n",
       " 'C_STD_T_F_AVG_FA_24M_RT',\n",
       " 'CM_STD_AVG_AP_FA_24M_RT',\n",
       " 'C_PD_MAX_FA_24M_RT',\n",
       " 'C_PD_MAX_P_FA_24M_RT',\n",
       " 'C_D_MAX_G_FA_24M_RT',\n",
       " 'C_PD_MAX_T_FA_24M_RT',\n",
       " 'CM_D_MAX_AP_FA_24M_RT',\n",
       " 'CM_PD_MAX_AP_FA_24M_RT',\n",
       " 'C_D_FA_AVG_24M_RT',\n",
       " 'C_P_STN_APPR_24M_RT_IND',\n",
       " 'C_G_STN_APPR_24M_RT_IND',\n",
       " 'C_ATT_CNT_18M_RT',\n",
       " 'C_ATT_DLR_18M_RT',\n",
       " 'C_STD_ATT_FA_18M_RT',\n",
       " 'C_STA_ATT_CNT_18M_RT',\n",
       " 'C_SAME_CHN_ATT_18M_RT',\n",
       " 'C_SAME_Z4_ATT_18M_RT',\n",
       " 'C_SAME_Z3_ATT_18M_RT',\n",
       " 'CM_ATT_CNT_18M_RT',\n",
       " 'CM_MAX_ATT_FA_18M_RT',\n",
       " 'C_APPR_CNT_18M_RT',\n",
       " 'C_UNPD_CLM_CNT_18M_RT',\n",
       " 'CM_APPR_CNT_18M_RT',\n",
       " 'CM_MAX_APPR_FA_18M_RT',\n",
       " 'C_DECL_DLR_18M_EX_RT',\n",
       " 'C_STR_CNT_DECL_SSN_18M_RT',\n",
       " 'C_Z5_DECL_18M_RT',\n",
       " 'C_SAME_CHN_DECL_18M_RT',\n",
       " 'C_SAME_Z5_DECL_18M_RT',\n",
       " 'C_MAX_P_FA_APPR_18M_RT',\n",
       " 'C_PAID_P_CLM_CNT_18M_RT',\n",
       " 'C_UNPD_P_CLM_DLR_18M_RT',\n",
       " 'C_G_APPR_CNT_18M_RT',\n",
       " 'C_SAME_STR_G_APP_18M_RT',\n",
       " 'C_PAID_G_CLM_DLR_18M_RT',\n",
       " 'C_UNPD_G_CLM_DLR_18M_RT',\n",
       " 'C_G_GLR_18M_RT',\n",
       " 'C_T_APPR_CNT_18M_RT',\n",
       " 'C_SAME_STR_T_APP_18M_RT',\n",
       " 'C_UNPD_T_CLM_CNT_18M_RT',\n",
       " 'C_T_GLR_18M_RT',\n",
       " 'C_T_NLR_18M_RT',\n",
       " 'CM_STD_AVG_FA_18M_RT',\n",
       " 'C_D_MAX_G_FA_18M_RT',\n",
       " 'C_PD_MAX_G_FA_18M_RT',\n",
       " 'C_PD_MAX_T_FA_18M_RT',\n",
       " 'CM_D_MAX_FA_18M_RT',\n",
       " 'C_DLR_DECL_RATE_18M_RT',\n",
       " 'C_FA_PD_AVG_18M_RT',\n",
       " 'C_G_STN_APPR_18M_RT_IND',\n",
       " 'C_T_STN_APPR_18M_RT_IND',\n",
       " 'C_ATT_DLR_12M_RT',\n",
       " 'C_SAME_Z3_ATT_12M_RT',\n",
       " 'CM_ATT_CNT_12M_RT',\n",
       " 'C_APPR_DLR_12M_RT',\n",
       " 'C_UNPD_CLM_DLR_12M_RT',\n",
       " 'C_GLR_12M_RT',\n",
       " 'C_NLR_12M_RT',\n",
       " 'C_STA_APPR_CNT_12M_RT',\n",
       " 'C_SAME_STR_APPR_12M_RT',\n",
       " 'C_SAME_Z5_APPR_12M_RT',\n",
       " 'CM_APPR_CNT_12M_RT',\n",
       " 'C_DECL_CNT_12M_EX_RT',\n",
       " 'C_CHN_DECL_CNT_12M_RT',\n",
       " 'C_Z5_DECL_12M_RT',\n",
       " 'C_SAME_STR_DECL_12M_RT',\n",
       " 'C_P_APPR_CNT_12M_RT',\n",
       " 'C_MAX_P_FA_APPR_12M_RT',\n",
       " 'C_UNPD_P_CLM_CNT_12M_RT',\n",
       " 'C_P_GLR_12M_RT',\n",
       " 'C_P_NLR_12M_RT',\n",
       " 'C_MAX_G_FA_APPR_12M_RT',\n",
       " 'C_SAME_STR_G_APP_12M_RT',\n",
       " 'C_PAID_G_CLM_DLR_12M_RT',\n",
       " 'C_UNPD_G_CLM_CNT_12M_RT',\n",
       " 'C_UNPD_G_CLM_DLR_12M_RT',\n",
       " 'C_SAME_STR_T_APP_12M_RT',\n",
       " 'C_T_GLR_12M_RT',\n",
       " 'C_STD_G_F_AVG_FA_12M_RT',\n",
       " 'C_D_MAX_FA_12M_RT',\n",
       " 'C_PD_MAX_FA_12M_RT',\n",
       " 'C_D_MAX_P_FA_12M_RT',\n",
       " 'C_PD_MAX_T_FA_12M_RT',\n",
       " 'CM_PD_MAX_FA_12M_RT',\n",
       " 'CM_D_MAX_AP_FA_12M_RT',\n",
       " 'C_UNIT_DECL_RATE_12M_RT',\n",
       " 'C_DLR_DECL_RATE_12M_RT',\n",
       " 'C_FA_PD_AVG_12M_RT',\n",
       " 'C_ATT_DLR_6M_RT',\n",
       " 'CM_MAX_ATT_FA_6M_RT',\n",
       " 'C_APPR_CNT_6M_RT',\n",
       " 'C_STD_APPR_FA_6M_RT',\n",
       " 'C_PAID_CLM_CNT_6M_RT',\n",
       " 'C_UNPD_CLM_CNT_6M_RT',\n",
       " 'C_GLR_6M_RT',\n",
       " 'C_NLR_6M_RT',\n",
       " 'C_STA_APPR_CNT_6M_RT',\n",
       " 'C_SAME_CHN_APPR_6M_RT',\n",
       " 'C_SAME_STR_APPR_6M_RT',\n",
       " 'C_DECL_DLR_6M_EX_RT',\n",
       " 'C_CHN_DECL_CNT_6M_RT',\n",
       " 'C_STR_CNT_DECL_SSN_6M_RT',\n",
       " 'C_SAME_CHN_DECL_6M_RT',\n",
       " 'CM_DECL_CNT_6M_RT',\n",
       " 'C_P_APPR_CNT_6M_RT',\n",
       " 'C_UNPD_P_CLM_CNT_6M_RT',\n",
       " 'C_UNPD_P_CLM_DLR_6M_RT',\n",
       " 'C_G_APPR_DLR_6M_RT',\n",
       " 'C_MAX_G_FA_APPR_6M_RT',\n",
       " 'C_SAME_STR_G_APP_6M_RT',\n",
       " 'C_PAID_G_CLM_CNT_6M_RT',\n",
       " 'C_PAID_G_CLM_DLR_6M_RT',\n",
       " 'C_UNPD_G_CLM_DLR_6M_RT',\n",
       " 'C_G_GLR_6M_RT',\n",
       " 'C_G_NLR_6M_RT',\n",
       " 'C_MAX_T_FA_APPR_6M_RT',\n",
       " 'C_PAID_T_CLM_CNT_6M_RT',\n",
       " 'C_UNPD_T_CLM_DLR_6M_RT',\n",
       " 'C_CLM_DLR_6M_RT',\n",
       " 'C_STD_F_AVG_FA_6M_RT',\n",
       " 'C_STD_G_F_AVG_FA_6M_RT',\n",
       " 'CM_STD_AVG_AP_FA_6M_RT',\n",
       " 'C_PD_MAX_FA_6M_RT',\n",
       " 'C_D_MAX_P_FA_6M_RT',\n",
       " 'C_PD_MAX_T_FA_6M_RT',\n",
       " 'CM_D_MAX_FA_6M_RT',\n",
       " 'CM_D_MAX_AP_FA_6M_RT',\n",
       " 'C_FA_PD_AVG_6M_RT',\n",
       " 'C_ATT_CNT_3M_RT',\n",
       " 'C_ATT_DLR_3M_RT',\n",
       " 'C_STD_ATT_FA_3M_RT',\n",
       " 'C_Z5_ATT_CNT_3M_RT',\n",
       " 'C_SAME_STR_ATT_3M_RT',\n",
       " 'C_SAME_Z4_ATT_3M_RT',\n",
       " 'C_SAME_Z3_ATT_3M_RT',\n",
       " 'CM_ATT_CNT_3M_RT',\n",
       " 'C_APPR_DLR_3M_RT',\n",
       " 'C_MAX_APPR_FA_3M_RT',\n",
       " 'C_PAID_CLM_DLR_3M_RT',\n",
       " 'C_UNPD_CLM_CNT_3M_RT',\n",
       " 'C_SAME_STR_APPR_3M_RT',\n",
       " 'CM_MAX_APPR_FA_3M_RT',\n",
       " 'C_CHN_DECL_CNT_3M_RT',\n",
       " 'C_STR_CNT_DECL_SSN_3M_RT',\n",
       " 'C_Z5_DECL_3M_RT',\n",
       " 'C_SAME_CHN_DECL_3M_RT',\n",
       " 'C_SAME_Z5_DECL_3M_RT',\n",
       " 'C_SAME_Z4_DECL_3M_RT',\n",
       " 'CM_DECL_CNT_3M_RT',\n",
       " 'C_P_APPR_DLR_3M_RT',\n",
       " 'C_SAME_STR_P_APP_3M_RT',\n",
       " 'C_P_NLR_3M_RT',\n",
       " 'C_G_APPR_DLR_3M_RT',\n",
       " 'C_SAME_STR_G_APP_3M_RT',\n",
       " 'C_PAID_G_CLM_CNT_3M_RT',\n",
       " 'C_T_APPR_CNT_3M_RT',\n",
       " 'C_T_APPR_DLR_3M_RT',\n",
       " 'C_MAX_T_FA_APPR_3M_RT',\n",
       " 'C_PAID_T_CLM_CNT_3M_RT',\n",
       " 'C_PAID_T_CLM_DLR_3M_RT',\n",
       " 'C_UNPD_T_CLM_CNT_3M_RT',\n",
       " 'C_UNPD_T_CLM_DLR_3M_RT',\n",
       " 'C_P_CLM_CNT_3M_RT',\n",
       " 'C_STD_P_F_AVG_FA_3M_RT',\n",
       " 'C_STD_G_F_AVG_FA_3M_RT',\n",
       " 'CM_STD_AVG_FA_3M_RT',\n",
       " 'C_PD_MAX_FA_3M_RT',\n",
       " 'C_D_MAX_P_FA_3M_RT',\n",
       " 'C_D_MAX_T_FA_3M_RT',\n",
       " 'CM_D_MAX_FA_3M_RT',\n",
       " 'CM_PD_MAX_AP_FA_3M_RT',\n",
       " 'C_FA_PD_AVG_3M_RT',\n",
       " 'C_R_STA_DECL_CNT_3M_RT',\n",
       " 'C_P_STN_APPR_3M_RT_IND',\n",
       " 'C_ATT_CNT_60D_RT',\n",
       " 'C_MAX_ATT_FA_60D_RT',\n",
       " 'C_STA_ATT_CNT_60D_RT',\n",
       " 'C_Z5_ATT_CNT_60D_RT',\n",
       " 'C_SAME_STR_ATT_60D_RT',\n",
       " 'C_SAME_Z5_ATT_60D_RT',\n",
       " 'CM_ATT_CNT_60D_RT',\n",
       " 'CM_MAX_ATT_FA_60D_RT',\n",
       " 'C_PAID_CLM_DLR_60D_RT',\n",
       " 'C_UNPD_CLM_DLR_60D_RT',\n",
       " 'C_NLR_60D_RT',\n",
       " 'C_STA_APPR_CNT_60D_RT',\n",
       " 'C_SAME_CHN_APPR_60D_RT',\n",
       " 'C_SAME_STR_APPR_60D_RT',\n",
       " 'C_SAME_Z4_APPR_60D_RT',\n",
       " 'C_SAME_Z3_APPR_60D_RT',\n",
       " 'CM_APPR_CNT_60D_RT',\n",
       " 'CM_MAX_APPR_FA_60D_RT',\n",
       " 'C_DECL_DLR_60D_EX_RT',\n",
       " 'C_G_APPR_DLR_60D_RT',\n",
       " 'C_MAX_G_FA_APPR_60D_RT',\n",
       " 'C_PAID_G_CLM_CNT_60D_RT',\n",
       " 'C_G_GLR_60D_RT',\n",
       " 'C_T_APPR_CNT_60D_RT',\n",
       " 'C_T_APPR_DLR_60D_RT',\n",
       " 'C_MAX_T_FA_APPR_60D_RT',\n",
       " 'C_PAID_T_CLM_DLR_60D_RT',\n",
       " 'C_UNPD_T_CLM_CNT_60D_RT',\n",
       " 'C_UNPD_T_CLM_DLR_60D_RT',\n",
       " 'C_T_NLR_60D_RT',\n",
       " 'C_STD_T_F_AVG_FA_60D_RT',\n",
       " 'CM_STD_AVG_AP_FA_60D_RT',\n",
       " 'CM_STD_AVG_FA_60D_RT',\n",
       " 'C_PD_MAX_FA_60D_RT',\n",
       " 'C_D_MAX_P_FA_60D_RT',\n",
       " 'C_UNIT_DECL_RATE_60D_RT',\n",
       " 'C_DLR_DECL_RATE_60D_RT',\n",
       " 'C_D_FA_AVG_60D_RT',\n",
       " 'C_P_STN_APPR_60D_RT_IND',\n",
       " 'C_MAX_ATT_FA_30D_RT',\n",
       " 'C_STA_ATT_CNT_30D_RT',\n",
       " 'C_SAME_CHN_ATT_30D_RT',\n",
       " 'C_SAME_Z4_ATT_30D_RT',\n",
       " 'CM_ATT_CNT_30D_RT',\n",
       " 'C_UNPD_CLM_DLR_30D_RT',\n",
       " 'C_SAME_CHN_APPR_30D_RT',\n",
       " 'C_SAME_STR_APPR_30D_RT',\n",
       " 'CM_MAX_APPR_FA_30D_RT',\n",
       " 'C_DECL_DLR_30D_EX_RT',\n",
       " 'C_Z5_DECL_30D_RT',\n",
       " 'C_SAME_CHN_DECL_30D_RT',\n",
       " 'C_SAME_Z4_DECL_30D_RT',\n",
       " 'CM_DECL_CNT_30D_RT',\n",
       " 'C_PAID_P_CLM_CNT_30D_RT',\n",
       " 'C_UNPD_P_CLM_CNT_30D_RT',\n",
       " 'C_P_GLR_30D_RT',\n",
       " 'C_PAID_G_CLM_CNT_30D_RT',\n",
       " 'C_T_APPR_CNT_30D_RT',\n",
       " 'C_PAID_T_CLM_DLR_30D_RT',\n",
       " 'C_CLM_DLR_30D_RT',\n",
       " 'C_P_CLM_CNT_30D_RT',\n",
       " 'C_STD_P_F_AVG_FA_30D_RT',\n",
       " 'C_STD_G_F_AVG_FA_30D_RT',\n",
       " 'CM_STD_AVG_AP_FA_30D_RT',\n",
       " 'CM_STD_AVG_FA_30D_RT',\n",
       " 'C_PD_MAX_G_FA_30D_RT',\n",
       " 'CM_D_MAX_FA_30D_RT',\n",
       " 'C_UNIT_DECL_RATE_30D_RT',\n",
       " 'C_DLR_DECL_RATE_30D_RT',\n",
       " 'C_P_STN_APPR_30D_RT_IND',\n",
       " 'C_G_STN_APPR_30D_RT_IND',\n",
       " 'C_STD_ATT_FA_21D_RT',\n",
       " 'C_SAME_STR_ATT_21D_RT',\n",
       " 'C_SAME_Z3_ATT_21D_RT',\n",
       " 'C_APPR_CNT_21D_RT',\n",
       " 'C_MAX_APPR_FA_21D_RT',\n",
       " 'C_UNPD_CLM_CNT_21D_RT',\n",
       " 'C_UNPD_CLM_DLR_21D_RT',\n",
       " 'C_GLR_21D_RT',\n",
       " 'C_SAME_STR_APPR_21D_RT',\n",
       " 'C_SAME_Z3_APPR_21D_RT',\n",
       " 'CM_APPR_CNT_21D_RT',\n",
       " 'CM_MAX_APPR_FA_21D_RT',\n",
       " 'C_DECL_CNT_21D_RT',\n",
       " 'C_DECL_CNT_21D_EX_RT',\n",
       " 'C_DECL_DLR_21D_RT',\n",
       " 'C_STR_CNT_DECL_SSN_21D_RT',\n",
       " 'C_Z5_DECL_21D_RT',\n",
       " 'C_SAME_CHN_DECL_21D_RT',\n",
       " 'C_SAME_STR_DECL_21D_RT',\n",
       " 'C_P_APPR_CNT_21D_RT',\n",
       " 'C_P_APPR_DLR_21D_RT',\n",
       " 'C_PAID_P_CLM_CNT_21D_RT',\n",
       " 'C_PAID_P_CLM_DLR_21D_RT',\n",
       " 'C_UNPD_P_CLM_CNT_21D_RT',\n",
       " 'C_MAX_G_FA_APPR_21D_RT',\n",
       " 'C_SAME_STR_G_APP_21D_RT',\n",
       " 'C_UNPD_G_CLM_DLR_21D_RT',\n",
       " 'C_G_GLR_21D_RT',\n",
       " 'C_G_NLR_21D_RT',\n",
       " 'C_PAID_T_CLM_CNT_21D_RT',\n",
       " 'C_UNPD_T_CLM_CNT_21D_RT',\n",
       " 'C_T_GLR_21D_RT',\n",
       " 'C_CLM_DLR_21D_RT',\n",
       " 'C_STD_F_AVG_FA_21D_RT',\n",
       " 'C_STD_G_F_AVG_FA_21D_RT',\n",
       " 'C_STD_T_F_AVG_FA_21D_RT',\n",
       " 'C_D_MAX_T_FA_21D_RT',\n",
       " 'CM_D_MAX_FA_21D_RT',\n",
       " 'CM_PD_MAX_AP_FA_21D_RT',\n",
       " 'C_UNIT_DECL_RATE_21D_RT',\n",
       " 'C_DLR_DECL_RATE_21D_RT',\n",
       " 'C_FA_PD_AVG_21D_RT',\n",
       " 'C_R_STA_DECL_CNT_21D_RT',\n",
       " 'C_P_STN_APPR_21D_RT_IND',\n",
       " 'C_STD_ATT_FA_18D_RT',\n",
       " 'C_SAME_CHN_ATT_18D_RT',\n",
       " 'C_SAME_Z4_ATT_18D_RT',\n",
       " 'C_SAME_Z3_ATT_18D_RT',\n",
       " 'CM_ATT_CNT_18D_RT',\n",
       " 'C_APPR_CNT_18D_RT',\n",
       " 'C_APPR_DLR_18D_RT',\n",
       " 'C_PAID_CLM_CNT_18D_RT',\n",
       " 'C_PAID_CLM_DLR_18D_RT',\n",
       " 'C_UNPD_CLM_CNT_18D_RT',\n",
       " 'C_UNPD_CLM_DLR_18D_RT',\n",
       " 'C_GLR_18D_RT',\n",
       " 'C_SAME_Z3_APPR_18D_RT',\n",
       " 'CM_MAX_APPR_FA_18D_RT',\n",
       " 'C_DECL_DLR_18D_RT',\n",
       " 'C_STR_CNT_DECL_SSN_18D_RT',\n",
       " 'C_SAME_CHN_DECL_18D_RT',\n",
       " 'C_SAME_Z5_DECL_18D_RT',\n",
       " 'C_SAME_STR_P_APP_18D_RT',\n",
       " 'C_P_GLR_18D_RT',\n",
       " 'C_P_NLR_18D_RT',\n",
       " 'C_G_APPR_DLR_18D_RT',\n",
       " 'C_PAID_G_CLM_CNT_18D_RT',\n",
       " 'C_UNPD_G_CLM_DLR_18D_RT',\n",
       " 'C_T_APPR_CNT_18D_RT',\n",
       " 'C_UNPD_T_CLM_DLR_18D_RT',\n",
       " 'C_T_GLR_18D_RT',\n",
       " 'C_CLM_DLR_18D_RT',\n",
       " 'C_P_CLM_CNT_18D_RT',\n",
       " 'C_STD_F_AVG_FA_18D_RT',\n",
       " 'C_STD_T_F_AVG_FA_18D_RT',\n",
       " 'CM_STD_AVG_AP_FA_18D_RT',\n",
       " 'C_D_MAX_P_FA_18D_RT',\n",
       " 'C_D_MAX_G_FA_18D_RT',\n",
       " 'CM_D_MAX_AP_FA_18D_RT',\n",
       " 'C_UNIT_DECL_RATE_18D_RT',\n",
       " 'C_D_FA_AVG_18D_RT',\n",
       " 'C_R_STA_DECL_CNT_18D_RT',\n",
       " 'C_T_STN_APPR_18D_RT_IND',\n",
       " 'C_MAX_ATT_FA_14D_RT',\n",
       " 'C_SAME_STR_ATT_14D_RT',\n",
       " 'CM_MAX_ATT_FA_14D_RT',\n",
       " 'C_APPR_CNT_14D_RT',\n",
       " 'C_UNPD_CLM_DLR_14D_RT',\n",
       " 'C_SAME_CHN_APPR_14D_RT',\n",
       " 'CM_APPR_CNT_14D_RT',\n",
       " 'CM_MAX_APPR_FA_14D_RT',\n",
       " 'C_DECL_CNT_14D_EX_RT',\n",
       " 'C_DECL_DLR_14D_RT',\n",
       " 'C_STR_CNT_DECL_SSN_14D_RT',\n",
       " 'C_SAME_CHN_DECL_14D_RT',\n",
       " 'C_SAME_Z5_DECL_14D_RT',\n",
       " 'C_SAME_Z4_DECL_14D_RT',\n",
       " 'C_P_APPR_DLR_14D_RT',\n",
       " 'C_MAX_P_FA_APPR_14D_RT',\n",
       " 'C_SAME_STR_P_APP_14D_RT',\n",
       " 'C_PAID_P_CLM_CNT_14D_RT',\n",
       " 'C_UNPD_P_CLM_CNT_14D_RT',\n",
       " 'C_PAID_G_CLM_CNT_14D_RT',\n",
       " 'C_G_GLR_14D_RT',\n",
       " 'C_T_APPR_CNT_14D_RT',\n",
       " 'C_T_APPR_DLR_14D_RT',\n",
       " 'C_PAID_T_CLM_CNT_14D_RT',\n",
       " 'C_T_NLR_14D_RT',\n",
       " 'CM_STD_AVG_AP_FA_14D_RT',\n",
       " 'C_D_MAX_FA_14D_RT',\n",
       " 'C_PD_MAX_FA_14D_RT',\n",
       " 'C_D_MAX_T_FA_14D_RT',\n",
       " 'CM_D_MAX_FA_14D_RT',\n",
       " 'CM_PD_MAX_FA_14D_RT',\n",
       " 'CM_PD_MAX_AP_FA_14D_RT',\n",
       " 'C_UNIT_DECL_RATE_14D_RT',\n",
       " 'C_D_FA_AVG_14D_RT',\n",
       " 'C_FA_PD_AVG_14D_RT',\n",
       " 'C_R_STA_DECL_CNT_14D_RT',\n",
       " 'C_G_STN_APPR_14D_RT_IND',\n",
       " 'C_ATT_CNT_7D_RT',\n",
       " 'C_ATT_DLR_7D_RT',\n",
       " 'C_STD_ATT_FA_7D_RT',\n",
       " 'C_MAX_ATT_FA_7D_RT',\n",
       " 'C_SAME_Z3_ATT_7D_RT',\n",
       " 'C_APPR_CNT_7D_RT',\n",
       " 'C_PAID_CLM_CNT_7D_RT',\n",
       " 'C_NLR_7D_RT',\n",
       " 'C_STA_APPR_CNT_7D_RT',\n",
       " 'C_SAME_STR_APPR_7D_RT',\n",
       " 'C_SAME_Z4_APPR_7D_RT',\n",
       " 'CM_MAX_APPR_FA_7D_RT',\n",
       " 'C_DECL_CNT_7D_EX_RT',\n",
       " 'C_CHN_DECL_CNT_7D_RT',\n",
       " 'C_SAME_CHN_DECL_7D_RT',\n",
       " 'C_SAME_Z3_DECL_7D_RT',\n",
       " 'C_P_APPR_DLR_7D_RT',\n",
       " 'C_MAX_P_FA_APPR_7D_RT',\n",
       " 'C_PAID_P_CLM_CNT_7D_RT',\n",
       " 'C_UNPD_P_CLM_DLR_7D_RT',\n",
       " 'C_P_GLR_7D_RT',\n",
       " 'C_P_NLR_7D_RT',\n",
       " 'C_G_APPR_DLR_7D_RT',\n",
       " 'C_PAID_G_CLM_DLR_7D_RT',\n",
       " 'C_G_GLR_7D_RT',\n",
       " 'C_G_NLR_7D_RT',\n",
       " 'C_SAME_STR_T_APP_7D_RT',\n",
       " 'C_T_GLR_7D_RT',\n",
       " 'C_T_NLR_7D_RT',\n",
       " 'C_CLM_DLR_7D_RT',\n",
       " 'CM_STD_AVG_FA_7D_RT',\n",
       " 'C_PD_MAX_G_FA_7D_RT',\n",
       " 'C_D_MAX_T_FA_7D_RT',\n",
       " 'C_PD_MAX_T_FA_7D_RT',\n",
       " 'CM_PD_MAX_FA_7D_RT',\n",
       " 'CM_PD_MAX_AP_FA_7D_RT',\n",
       " 'C_DLR_DECL_RATE_7D_RT',\n",
       " 'C_R_STA_DECL_CNT_7D_RT',\n",
       " 'C_T_STN_APPR_7D_RT_IND',\n",
       " 'C_MAX_ATT_FA_3D_RT',\n",
       " 'C_SAME_Z5_ATT_3D_RT',\n",
       " 'C_PAID_CLM_CNT_3D_RT',\n",
       " 'C_UNPD_CLM_DLR_3D_RT',\n",
       " 'C_GLR_3D_RT',\n",
       " 'C_NLR_3D_RT',\n",
       " 'C_STA_APPR_CNT_3D_RT',\n",
       " 'C_SAME_CHN_APPR_3D_RT',\n",
       " 'C_SAME_STR_APPR_3D_RT',\n",
       " 'C_SAME_Z4_APPR_3D_RT',\n",
       " 'CM_APPR_CNT_3D_RT',\n",
       " 'C_DECL_CNT_3D_EX_RT',\n",
       " 'C_CHN_DECL_CNT_3D_RT',\n",
       " 'C_Z5_DECL_3D_RT',\n",
       " 'C_SAME_CHN_DECL_3D_RT',\n",
       " 'C_SAME_STR_DECL_3D_RT',\n",
       " 'C_SAME_Z4_DECL_3D_RT',\n",
       " 'C_SAME_Z3_DECL_3D_RT',\n",
       " 'C_G_APPR_DLR_3D_RT',\n",
       " 'C_UNPD_G_CLM_DLR_3D_RT',\n",
       " 'C_MAX_T_FA_APPR_3D_RT',\n",
       " 'C_T_GLR_3D_RT',\n",
       " 'C_T_NLR_3D_RT',\n",
       " 'C_P_CLM_CNT_3D_RT',\n",
       " 'C_STD_F_AVG_FA_3D_RT',\n",
       " 'C_STD_P_F_AVG_FA_3D_RT',\n",
       " 'C_STD_G_F_AVG_FA_3D_RT',\n",
       " 'C_D_MAX_G_FA_3D_RT',\n",
       " 'C_PD_MAX_G_FA_3D_RT',\n",
       " 'C_R_STA_DECL_CNT_3D_RT',\n",
       " 'C_Z5_ATT_CNT_1D_RT',\n",
       " 'C_SAME_Z5_ATT_1D_RT',\n",
       " 'CM_ATT_CNT_1D_RT',\n",
       " 'C_STD_APPR_FA_1D_RT',\n",
       " 'C_PAID_CLM_CNT_1D_RT',\n",
       " 'C_PAID_CLM_DLR_1D_RT',\n",
       " 'C_UNPD_CLM_DLR_1D_RT',\n",
       " 'C_Z5_APPR_CNT_1D_RT',\n",
       " 'C_SAME_CHN_APPR_1D_RT',\n",
       " 'C_SAME_Z4_APPR_1D_RT',\n",
       " 'C_SAME_Z3_APPR_1D_RT',\n",
       " 'C_DECL_DLR_1D_RT',\n",
       " 'C_DECL_DLR_1D_EX_RT',\n",
       " 'C_CHN_DECL_CNT_1D_RT',\n",
       " 'C_Z5_DECL_1D_RT',\n",
       " 'C_SAME_STR_DECL_1D_RT',\n",
       " 'C_SAME_Z4_DECL_1D_RT',\n",
       " 'C_SAME_Z3_DECL_1D_RT',\n",
       " 'CM_DECL_CNT_1D_RT',\n",
       " 'C_P_APPR_DLR_1D_RT',\n",
       " 'C_MAX_P_FA_APPR_1D_RT',\n",
       " 'C_SAME_STR_P_APP_1D_RT',\n",
       " 'C_P_GLR_1D_RT',\n",
       " 'C_P_NLR_1D_RT',\n",
       " 'C_G_APPR_DLR_1D_RT',\n",
       " 'C_PAID_G_CLM_DLR_1D_RT',\n",
       " 'C_UNPD_G_CLM_CNT_1D_RT',\n",
       " 'C_G_NLR_1D_RT',\n",
       " 'C_PAID_T_CLM_CNT_1D_RT',\n",
       " 'C_PAID_T_CLM_DLR_1D_RT',\n",
       " 'C_T_GLR_1D_RT',\n",
       " 'C_STD_F_AVG_FA_1D_RT',\n",
       " 'CM_STD_AVG_FA_1D_RT',\n",
       " 'C_PD_MAX_FA_1D_RT',\n",
       " 'C_D_MAX_P_FA_1D_RT',\n",
       " 'C_D_MAX_G_FA_1D_RT',\n",
       " 'C_PD_MAX_G_FA_1D_RT',\n",
       " 'C_PD_MAX_T_FA_1D_RT',\n",
       " 'CM_D_MAX_FA_1D_RT',\n",
       " 'CM_PD_MAX_FA_1D_RT',\n",
       " 'CM_PD_MAX_AP_FA_1D_RT',\n",
       " 'C_UNIT_DECL_RATE_1D_RT',\n",
       " 'C_D_FA_AVG_1D_RT',\n",
       " 'C_FA_PD_AVG_1D_RT',\n",
       " 'C_R_STA_DECL_CNT_1D_RT',\n",
       " 'C_P_STN_APPR_1D_RT_IND',\n",
       " 'C_G_STN_APPR_1D_RT_IND',\n",
       " 'C_ATT_CNT_7D_L1',\n",
       " 'C_APPR_CNT_6M_L14',\n",
       " 'C_APPR_CNT_6M_L7',\n",
       " 'C_APPR_CNT_3M_L14',\n",
       " 'C_APPR_CNT_3M_L7',\n",
       " 'C_APPR_CNT_30D_L14',\n",
       " 'C_APPR_CNT_30D_L7',\n",
       " 'CM_APPR_CNT_24M_L1',\n",
       " 'CM_APPR_CNT_12M_L14',\n",
       " 'CM_APPR_CNT_12M_L7',\n",
       " 'CM_APPR_CNT_12M_L1',\n",
       " 'CM_APPR_CNT_6M_L1',\n",
       " 'CM_APPR_CNT_3M_L7',\n",
       " 'C_APPR_DLR_6M_L7',\n",
       " 'C_SAME_Z4_APPR_24M_L7',\n",
       " 'C_SAME_CHN_APPR_24M_L7',\n",
       " 'C_SAME_Z5_APPR_12M_L14',\n",
       " 'C_SAME_Z5_APPR_12M_L7',\n",
       " 'C_SAME_CHN_APPR_12M_L7',\n",
       " 'C_SAME_STR_APPR_6M_L14',\n",
       " 'C_SAME_Z5_APPR_6M_L14',\n",
       " 'C_SAME_Z3_APPR_6M_L14',\n",
       " 'C_SAME_Z3_APPR_6M_L7',\n",
       " 'C_SAME_CHN_APPR_6M_L14',\n",
       " 'C_SAME_CHN_APPR_6M_L7',\n",
       " 'C_SAME_Z5_APPR_3M_L14',\n",
       " 'C_SAME_Z4_APPR_3M_L14',\n",
       " 'C_SAME_Z3_APPR_3M_L7',\n",
       " 'C_R_AV_APP_D_12M_14D_RT',\n",
       " 'C_R_AV_APP_D_6M_7D_RT',\n",
       " 'C_R_DLY_APPR_24M_14D_RT',\n",
       " 'C_R_DLY_APPR_12M_14D_RT',\n",
       " 'C_R_DLY_APPR_6M_3M_RT',\n",
       " 'C_STD_C_AVG_TIME_24M_RT',\n",
       " 'C_STD_C_AVG_TIME_6M_RT',\n",
       " 'C_STD_C_AVG_TIME_30D_RT',\n",
       " 'C_STD_C_AVG_TIME_18D_RT',\n",
       " 'C_STD_C_AVG_TIME_14D_RT',\n",
       " 'NAT_POSITIVE_GRADE_C',\n",
       " 'NAT_POSITIVE_GRADE_F',\n",
       " 'NAT_POSITIVE_GRADE_H',\n",
       " 'NAT_POSITIVE_GRADE_M',\n",
       " 'NAT_POSITIVE_GRADE_Q',\n",
       " 'NAT_POSITIVE_GRADE_T',\n",
       " 'NAT_POSITIVE_GRADE_W',\n",
       " 'NAT_POSITIVE_GRADE_Z',\n",
       " 'NAT_POSITIVE_GRADE_\\\\',\n",
       " 'NAT_POSITIVE_GRADE_^',\n",
       " 'ID_STATION_STATE_MATCH',\n",
       " 'ID_STATION_STATE_MIS-MATCH',\n",
       " 'ID_STATION_STATE_NON STATE ID',\n",
       " 'DAY_OF_WEEK_FRI',\n",
       " 'DAY_OF_WEEK_MON',\n",
       " 'DAY_OF_WEEK_SAT',\n",
       " 'DAY_OF_WEEK_SUN',\n",
       " 'DAY_OF_WEEK_THU',\n",
       " 'DAY_OF_WEEK_TUE',\n",
       " 'DAY_OF_WEEK_WED',\n",
       " 'ASIGN_AQUARIUS',\n",
       " 'ASIGN_ARIES',\n",
       " 'ASIGN_CANCER',\n",
       " 'ASIGN_CAPRICORN',\n",
       " 'ASIGN_GEMINI',\n",
       " 'ASIGN_LEO',\n",
       " 'ASIGN_LIBRA',\n",
       " 'ASIGN_PISCES',\n",
       " 'ASIGN_SAGITTARIUS',\n",
       " 'ASIGN_SCORPIO',\n",
       " 'ASIGN_TAURUS',\n",
       " 'ASIGN_VIRGO',\n",
       " 'ASIGN_Z']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now create a list of the features going into the model\n",
    "pred_attr = list(imputed_X_train.columns)\n",
    "pred_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting labels to arrays before calling \n",
    "imputed_X_train = np.asarray(imputed_X_train)\n",
    "y_train_bin = np.asarray(y_train_bin)\n",
    "imputed_X_val = np.asarray(imputed_X_val)\n",
    "y_val_bin = np.asarray(y_val_bin)\n",
    "\n",
    "imputed_X_deep_dive = np.asarray(imputed_X_deep_dive)\n",
    "\n",
    "#need number of features for the model definition\n",
    "input_shape = [imputed_X_train.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[125405]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_count = [imputed_X_train.shape[0]]\n",
    "sample_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.250391236306726"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_count = sample_count[0]/(5*(input_shape[0] + 1))\n",
    "neuron_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model\n",
    "model = keras.Sequential([\n",
    "    layers.BatchNormalization(input_shape=input_shape),\n",
    "    layers.Dense(15, activation='relu'),\n",
    "#    layers.BatchNormalization(),\n",
    "#    layers.Dropout(rate=0.3),\n",
    "#    layers.Dense(40, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "#    layers.Dropout(rate=0.3),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#compile the model with the Adam optimizer and binary versions of the cross-entropy loss and accuracy metric\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125405 samples, validate on 127210 samples\n",
      "Epoch 1/200\n",
      "125405/125405 [==============================] - 2s 19us/sample - loss: 0.7299 - binary_accuracy: 0.5239 - val_loss: 5.4232 - val_binary_accuracy: 0.9887\n",
      "Epoch 2/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.6641 - binary_accuracy: 0.6157 - val_loss: 4.9706 - val_binary_accuracy: 0.9887\n",
      "Epoch 3/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.6282 - binary_accuracy: 0.7810 - val_loss: 4.4715 - val_binary_accuracy: 0.9887\n",
      "Epoch 4/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.5962 - binary_accuracy: 0.9060 - val_loss: 4.0331 - val_binary_accuracy: 0.9887\n",
      "Epoch 5/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.5637 - binary_accuracy: 0.9542 - val_loss: 3.6566 - val_binary_accuracy: 0.9887\n",
      "Epoch 6/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.5297 - binary_accuracy: 0.9772 - val_loss: 3.3549 - val_binary_accuracy: 0.9887\n",
      "Epoch 7/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.4943 - binary_accuracy: 0.9842 - val_loss: 3.1018 - val_binary_accuracy: 0.9887\n",
      "Epoch 8/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.4581 - binary_accuracy: 0.9882 - val_loss: 2.8726 - val_binary_accuracy: 0.9887\n",
      "Epoch 9/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.4218 - binary_accuracy: 0.9895 - val_loss: 2.6604 - val_binary_accuracy: 0.9887\n",
      "Epoch 10/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.3861 - binary_accuracy: 0.9900 - val_loss: 2.4667 - val_binary_accuracy: 0.9887\n",
      "Epoch 11/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.3518 - binary_accuracy: 0.9902 - val_loss: 2.2876 - val_binary_accuracy: 0.9887\n",
      "Epoch 12/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.3194 - binary_accuracy: 0.9904 - val_loss: 2.1222 - val_binary_accuracy: 0.9887\n",
      "Epoch 13/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.2892 - binary_accuracy: 0.9905 - val_loss: 1.9725 - val_binary_accuracy: 0.9887\n",
      "Epoch 14/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.2615 - binary_accuracy: 0.9905 - val_loss: 1.8391 - val_binary_accuracy: 0.9887\n",
      "Epoch 15/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.2365 - binary_accuracy: 0.9906 - val_loss: 1.7103 - val_binary_accuracy: 0.9887\n",
      "Epoch 16/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.2141 - binary_accuracy: 0.9906 - val_loss: 1.5948 - val_binary_accuracy: 0.9887\n",
      "Epoch 17/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.1942 - binary_accuracy: 0.9906 - val_loss: 1.4875 - val_binary_accuracy: 0.9887\n",
      "Epoch 18/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.1767 - binary_accuracy: 0.9906 - val_loss: 1.3863 - val_binary_accuracy: 0.9887\n",
      "Epoch 19/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.1614 - binary_accuracy: 0.9906 - val_loss: 1.2909 - val_binary_accuracy: 0.9887\n",
      "Epoch 20/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.1480 - binary_accuracy: 0.9906 - val_loss: 1.2086 - val_binary_accuracy: 0.9887\n",
      "Epoch 21/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.1362 - binary_accuracy: 0.9906 - val_loss: 1.1310 - val_binary_accuracy: 0.9887\n",
      "Epoch 22/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.1261 - binary_accuracy: 0.9906 - val_loss: 1.0512 - val_binary_accuracy: 0.9887\n",
      "Epoch 23/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.1171 - binary_accuracy: 0.9906 - val_loss: 0.9796 - val_binary_accuracy: 0.9887\n",
      "Epoch 24/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.1095 - binary_accuracy: 0.9906 - val_loss: 0.9154 - val_binary_accuracy: 0.9887\n",
      "Epoch 25/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.1026 - binary_accuracy: 0.9906 - val_loss: 0.8549 - val_binary_accuracy: 0.9887\n",
      "Epoch 26/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0967 - binary_accuracy: 0.9906 - val_loss: 0.7985 - val_binary_accuracy: 0.9887\n",
      "Epoch 27/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0915 - binary_accuracy: 0.9906 - val_loss: 0.7470 - val_binary_accuracy: 0.9887\n",
      "Epoch 28/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0869 - binary_accuracy: 0.9906 - val_loss: 0.6987 - val_binary_accuracy: 0.9887\n",
      "Epoch 29/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0829 - binary_accuracy: 0.9906 - val_loss: 0.6544 - val_binary_accuracy: 0.9887\n",
      "Epoch 30/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0794 - binary_accuracy: 0.9906 - val_loss: 0.6127 - val_binary_accuracy: 0.9887\n",
      "Epoch 31/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0762 - binary_accuracy: 0.9906 - val_loss: 0.5719 - val_binary_accuracy: 0.9887\n",
      "Epoch 32/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0735 - binary_accuracy: 0.9906 - val_loss: 0.5344 - val_binary_accuracy: 0.9887\n",
      "Epoch 33/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0710 - binary_accuracy: 0.9906 - val_loss: 0.4981 - val_binary_accuracy: 0.9887\n",
      "Epoch 34/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0687 - binary_accuracy: 0.9906 - val_loss: 0.4663 - val_binary_accuracy: 0.9887\n",
      "Epoch 35/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0667 - binary_accuracy: 0.9906 - val_loss: 0.4359 - val_binary_accuracy: 0.9887\n",
      "Epoch 36/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0649 - binary_accuracy: 0.9906 - val_loss: 0.4091 - val_binary_accuracy: 0.9887\n",
      "Epoch 37/200\n",
      "125405/125405 [==============================] - 2s 14us/sample - loss: 0.0633 - binary_accuracy: 0.9906 - val_loss: 0.3816 - val_binary_accuracy: 0.9887\n",
      "Epoch 38/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0619 - binary_accuracy: 0.9906 - val_loss: 0.3565 - val_binary_accuracy: 0.9887\n",
      "Epoch 39/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0605 - binary_accuracy: 0.9906 - val_loss: 0.3319 - val_binary_accuracy: 0.9887\n",
      "Epoch 40/200\n",
      "125405/125405 [==============================] - 2s 14us/sample - loss: 0.0594 - binary_accuracy: 0.9906 - val_loss: 0.3106 - val_binary_accuracy: 0.9887\n",
      "Epoch 41/200\n",
      "125405/125405 [==============================] - 2s 14us/sample - loss: 0.0583 - binary_accuracy: 0.9906 - val_loss: 0.2928 - val_binary_accuracy: 0.9887\n",
      "Epoch 42/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0572 - binary_accuracy: 0.9906 - val_loss: 0.2842 - val_binary_accuracy: 0.9887\n",
      "Epoch 43/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0563 - binary_accuracy: 0.9906 - val_loss: 0.2899 - val_binary_accuracy: 0.9510\n",
      "Epoch 44/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0555 - binary_accuracy: 0.9906 - val_loss: 0.2736 - val_binary_accuracy: 0.9508\n",
      "Epoch 45/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0547 - binary_accuracy: 0.9906 - val_loss: 0.2498 - val_binary_accuracy: 0.9808\n",
      "Epoch 46/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0540 - binary_accuracy: 0.9906 - val_loss: 0.2349 - val_binary_accuracy: 0.9842\n",
      "Epoch 47/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0534 - binary_accuracy: 0.9906 - val_loss: 0.2146 - val_binary_accuracy: 0.9886\n",
      "Epoch 48/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0527 - binary_accuracy: 0.9906 - val_loss: 0.2010 - val_binary_accuracy: 0.9886\n",
      "Epoch 49/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0521 - binary_accuracy: 0.9906 - val_loss: 0.1896 - val_binary_accuracy: 0.9886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0516 - binary_accuracy: 0.9906 - val_loss: 0.1793 - val_binary_accuracy: 0.9886\n",
      "Epoch 51/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0512 - binary_accuracy: 0.9906 - val_loss: 0.1674 - val_binary_accuracy: 0.9886\n",
      "Epoch 52/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0507 - binary_accuracy: 0.9906 - val_loss: 0.1524 - val_binary_accuracy: 0.9887\n",
      "Epoch 53/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0502 - binary_accuracy: 0.9906 - val_loss: 0.1443 - val_binary_accuracy: 0.9887\n",
      "Epoch 54/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0499 - binary_accuracy: 0.9906 - val_loss: 0.1355 - val_binary_accuracy: 0.9887\n",
      "Epoch 55/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0495 - binary_accuracy: 0.9906 - val_loss: 0.1262 - val_binary_accuracy: 0.9886\n",
      "Epoch 56/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0491 - binary_accuracy: 0.9906 - val_loss: 0.1189 - val_binary_accuracy: 0.9886\n",
      "Epoch 57/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0488 - binary_accuracy: 0.9907 - val_loss: 0.1122 - val_binary_accuracy: 0.9887\n",
      "Epoch 58/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0485 - binary_accuracy: 0.9906 - val_loss: 0.1055 - val_binary_accuracy: 0.9887\n",
      "Epoch 59/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0481 - binary_accuracy: 0.9906 - val_loss: 0.0997 - val_binary_accuracy: 0.9887\n",
      "Epoch 60/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0479 - binary_accuracy: 0.9906 - val_loss: 0.0945 - val_binary_accuracy: 0.9887\n",
      "Epoch 61/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0478 - binary_accuracy: 0.9906 - val_loss: 0.0901 - val_binary_accuracy: 0.9886\n",
      "Epoch 62/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0474 - binary_accuracy: 0.9906 - val_loss: 0.0854 - val_binary_accuracy: 0.9886\n",
      "Epoch 63/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0474 - binary_accuracy: 0.9907 - val_loss: 0.0823 - val_binary_accuracy: 0.9886\n",
      "Epoch 64/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0470 - binary_accuracy: 0.9906 - val_loss: 0.0791 - val_binary_accuracy: 0.9886\n",
      "Epoch 65/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0468 - binary_accuracy: 0.9906 - val_loss: 0.0770 - val_binary_accuracy: 0.9886\n",
      "Epoch 66/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0466 - binary_accuracy: 0.9907 - val_loss: 0.0736 - val_binary_accuracy: 0.9886\n",
      "Epoch 67/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0464 - binary_accuracy: 0.9906 - val_loss: 0.0706 - val_binary_accuracy: 0.9886\n",
      "Epoch 68/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0463 - binary_accuracy: 0.9906 - val_loss: 0.0708 - val_binary_accuracy: 0.9886\n",
      "Epoch 69/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0459 - binary_accuracy: 0.9907 - val_loss: 0.0678 - val_binary_accuracy: 0.9886\n",
      "Epoch 70/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0459 - binary_accuracy: 0.9907 - val_loss: 0.0685 - val_binary_accuracy: 0.9886\n",
      "Epoch 71/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0458 - binary_accuracy: 0.9906 - val_loss: 0.0678 - val_binary_accuracy: 0.9886\n",
      "Epoch 72/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0455 - binary_accuracy: 0.9907 - val_loss: 0.0653 - val_binary_accuracy: 0.9886\n",
      "Epoch 73/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0454 - binary_accuracy: 0.9907 - val_loss: 0.0656 - val_binary_accuracy: 0.9886\n",
      "Epoch 74/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0452 - binary_accuracy: 0.9907 - val_loss: 0.0660 - val_binary_accuracy: 0.9886\n",
      "Epoch 75/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0451 - binary_accuracy: 0.9907 - val_loss: 0.0621 - val_binary_accuracy: 0.9886\n",
      "Epoch 76/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0449 - binary_accuracy: 0.9907 - val_loss: 0.0629 - val_binary_accuracy: 0.9886\n",
      "Epoch 77/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0449 - binary_accuracy: 0.9907 - val_loss: 0.0616 - val_binary_accuracy: 0.9886\n",
      "Epoch 78/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0448 - binary_accuracy: 0.9907 - val_loss: 0.0624 - val_binary_accuracy: 0.9886\n",
      "Epoch 79/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0447 - binary_accuracy: 0.9907 - val_loss: 0.0630 - val_binary_accuracy: 0.9886\n",
      "Epoch 80/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0447 - binary_accuracy: 0.9907 - val_loss: 0.0621 - val_binary_accuracy: 0.9886\n",
      "Epoch 81/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0443 - binary_accuracy: 0.9907 - val_loss: 0.0641 - val_binary_accuracy: 0.9885\n",
      "Epoch 82/200\n",
      "125405/125405 [==============================] - 2s 13us/sample - loss: 0.0442 - binary_accuracy: 0.9907 - val_loss: 0.0657 - val_binary_accuracy: 0.9884\n"
     ]
    }
   ],
   "source": [
    "#show time\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    min_delta=0.0001,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "history = model.fit(\n",
    "    imputed_X_train, y_train_bin,\n",
    "    validation_data=(imputed_X_val, y_val_bin),\n",
    "    batch_size=10000,\n",
    "    epochs=200,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\n",
    "history_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(title=\"Accuracy\")\n",
    "\n",
    "nn_pred = pd.DataFrame(model.predict_proba(imputed_X_val), columns = ['NEURAL_NET_PROB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        min_prob  max_prob  events  ...  cum_eventrate cum_noneventrate    KS\n",
      "Decile                              ...                                      \n",
      "0       0.051511  1.000000     120  ...          8.35%            1.93%   6.4\n",
      "1       0.039882  0.051499      95  ...         14.96%            3.88%  11.1\n",
      "2       0.033683  0.039879      86  ...         20.95%            5.83%  15.1\n",
      "3       0.029551  0.033683     104  ...         28.18%            7.77%  20.4\n",
      "4       0.026525  0.029550      70  ...         33.05%            9.74%  23.3\n",
      "5       0.024064  0.026523      60  ...         37.23%           11.71%  25.5\n",
      "6       0.021947  0.024063      61  ...         41.48%           13.69%  27.8\n",
      "7       0.020166  0.021944      58  ...         45.51%           15.66%  29.8\n",
      "8       0.018658  0.020165      55  ...         49.34%           17.64%  31.7\n",
      "9       0.017250  0.018658      51  ...         52.89%           19.62%  33.3\n",
      "10      0.015957  0.017250      51  ...         56.44%           21.61%  34.8\n",
      "11      0.014824  0.015956      40  ...         59.22%           23.60%  35.6\n",
      "12      0.013766  0.014824      46  ...         62.42%           25.58%  36.8\n",
      "13      0.012827  0.013766      26  ...         64.23%           27.59%  36.6\n",
      "14      0.011953  0.012826      34  ...         66.60%           29.58%  37.0\n",
      "15      0.011155  0.011953      38  ...         69.24%           31.57%  37.7\n",
      "16      0.010415  0.011155      38  ...         71.89%           33.57%  38.3\n",
      "17      0.009743  0.010414      26  ...         73.70%           35.57%  38.1\n",
      "18      0.009131  0.009743      30  ...         75.78%           37.57%  38.2\n",
      "19      0.008588  0.009130      28  ...         77.73%           39.57%  38.2\n",
      "20      0.008074  0.008588      21  ...         79.19%           41.57%  37.6\n",
      "21      0.007621  0.008074      19  ...         80.51%           43.58%  36.9\n",
      "22      0.007206  0.007621      15  ...         81.56%           45.59%  36.0\n",
      "23      0.006817  0.007206      22  ...         83.09%           47.60%  35.5\n",
      "24      0.006463  0.006817      19  ...         84.41%           49.61%  34.8\n",
      "25      0.006140  0.006462      15  ...         85.46%           51.62%  33.8\n",
      "26      0.005843  0.006140       8  ...         86.01%           53.63%  32.4\n",
      "27      0.005573  0.005843       7  ...         86.50%           55.65%  30.8\n",
      "28      0.005318  0.005573      19  ...         87.82%           57.66%  30.2\n",
      "29      0.005080  0.005318      13  ...         88.73%           59.67%  29.1\n",
      "30      0.004863  0.005080      12  ...         89.56%           61.68%  27.9\n",
      "31      0.004660  0.004863       8  ...         90.12%           63.70%  26.4\n",
      "32      0.004473  0.004660       7  ...         90.61%           65.72%  24.9\n",
      "33      0.004289  0.004473       7  ...         91.09%           67.74%  23.4\n",
      "34      0.004109  0.004288       9  ...         91.72%           69.75%  22.0\n",
      "35      0.003931  0.004109      14  ...         92.69%           71.76%  20.9\n",
      "36      0.003771  0.003931       8  ...         93.25%           73.78%  19.5\n",
      "37      0.003608  0.003771       9  ...         93.88%           75.80%  18.1\n",
      "38      0.003455  0.003608       5  ...         94.22%           77.81%  16.4\n",
      "39      0.003296  0.003455       5  ...         94.57%           79.83%  14.7\n",
      "40      0.003140  0.003296       9  ...         95.20%           81.85%  13.3\n",
      "41      0.002985  0.003140       7  ...         95.69%           83.87%  11.8\n",
      "42      0.002824  0.002985      10  ...         96.38%           85.88%  10.5\n",
      "43      0.002661  0.002824       8  ...         96.94%           87.90%   9.0\n",
      "44      0.002486  0.002661       4  ...         97.22%           89.92%   7.3\n",
      "45      0.002296  0.002486       7  ...         97.70%           91.93%   5.8\n",
      "46      0.002078  0.002296      12  ...         98.54%           93.95%   4.6\n",
      "47      0.001813  0.002078       9  ...         99.16%           95.96%   3.2\n",
      "48      0.001420  0.001813       6  ...         99.58%           97.98%   1.6\n",
      "49      0.000000  0.001420       6  ...        100.00%          100.00%   0.0\n",
      "\n",
      "[50 rows x 9 columns]\n",
      "\u001b[31mBottom Decile Capture:8.35%\n",
      "\u001b[31mKS is 38.3% at decile 16\n"
     ]
    }
   ],
   "source": [
    "#let see how this looks on a KS plot\n",
    "eval_df = pd.merge(nn_pred, pd.DataFrame(y_val_bin, columns=['FRAUD_IND']), how='inner', left_index=True, right_index=True)\n",
    "\n",
    "def ks(data=None,target=None, prob=None):\n",
    "    data['target0'] = 1 - data[target]\n",
    "    data['bucket'] = pd.qcut(data[prob], 50, duplicates=\"drop\")\n",
    "    grouped = data.groupby('bucket', as_index = False)\n",
    "    kstable = pd.DataFrame()\n",
    "    kstable['min_prob'] = grouped.min()[prob]\n",
    "    kstable['max_prob'] = grouped.max()[prob]\n",
    "    kstable['events']   = grouped.sum()[target]\n",
    "    kstable['nonevents'] = grouped.sum()['target0']\n",
    "    kstable = kstable.sort_values(by=\"min_prob\", ascending=False).reset_index(drop = True)\n",
    "    kstable['event_rate'] = (kstable.events / data[target].sum()).apply('{0:.2%}'.format)\n",
    "    kstable['nonevent_rate'] = (kstable.nonevents / data['target0'].sum()).apply('{0:.2%}'.format)\n",
    "    kstable['cum_eventrate']=(kstable.events / data[target].sum()).cumsum()\n",
    "    kstable['cum_noneventrate']=(kstable.nonevents / data['target0'].sum()).cumsum()\n",
    "    kstable['KS'] = np.round(kstable['cum_eventrate']-kstable['cum_noneventrate'], 3) * 100\n",
    "\n",
    "    #Formating\n",
    "    kstable['cum_eventrate']= kstable['cum_eventrate'].apply('{0:.2%}'.format)\n",
    "    kstable['cum_noneventrate']= kstable['cum_noneventrate'].apply('{0:.2%}'.format)\n",
    "    kstable.index = range(0,50)\n",
    "    kstable.index.rename('Decile', inplace=True)\n",
    "    pd.set_option('display.max_columns', 6)\n",
    "    print(kstable)\n",
    "    \n",
    "    #Display KS\n",
    "    from colorama import Fore\n",
    "    print(Fore.RED + \"Bottom Decile Capture:\" + str(kstable['cum_eventrate'][0]))\n",
    "    print(Fore.RED + \"KS is \" + str(max(kstable['KS']))+\"%\"+ \" at decile \" + str((kstable.index[kstable['KS']==max(kstable['KS'])][0])))\n",
    "    return(kstable)\n",
    "\n",
    "my_ks_df = ks(data=eval_df,target=\"FRAUD_IND\", prob=\"NEURAL_NET_PROB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TXN_UID</th>\n",
       "      <th>NEURAL_NET_PROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2705210000296</td>\n",
       "      <td>0.003269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2705210000299</td>\n",
       "      <td>0.004627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2705210000358</td>\n",
       "      <td>0.003669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2705210000366</td>\n",
       "      <td>0.008779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2705210000398</td>\n",
       "      <td>0.004647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307659</td>\n",
       "      <td>9006430014999</td>\n",
       "      <td>0.090475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307660</td>\n",
       "      <td>9006430015015</td>\n",
       "      <td>0.058014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307661</td>\n",
       "      <td>9006430015040</td>\n",
       "      <td>0.011123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307662</td>\n",
       "      <td>9006430015112</td>\n",
       "      <td>0.019441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307663</td>\n",
       "      <td>9006430015153</td>\n",
       "      <td>0.002273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307664 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              TXN_UID  NEURAL_NET_PROB\n",
       "0       2705210000296         0.003269\n",
       "1       2705210000299         0.004627\n",
       "2       2705210000358         0.003669\n",
       "3       2705210000366         0.008779\n",
       "4       2705210000398         0.004647\n",
       "...               ...              ...\n",
       "307659  9006430014999         0.090475\n",
       "307660  9006430015015         0.058014\n",
       "307661  9006430015040         0.011123\n",
       "307662  9006430015112         0.019441\n",
       "307663  9006430015153         0.002273\n",
       "\n",
       "[307664 rows x 2 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create data frame with txn_uid and score to export out for comparison with my SAS work \n",
    "probs_deep_dive = pd.DataFrame(model.predict_proba(imputed_X_deep_dive), columns = ['NEURAL_NET_PROB'])\n",
    "score_log_df = pd.merge(analysis_df['TXN_UID'], probs_deep_dive, how='inner', left_index=True, right_index=True)\n",
    "score_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export scores so that I can compare to the logistic regression model I completed in SAS\n",
    "score_log_df.to_csv(\"./Output/dup pres scores from neural net.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental.preprocessing'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-245-f21c603ab048>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscikit_learn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     raise ImportError(\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator <tensorflow.python.keras.engine.sequential.Sequential object at 0x000001BF995417C8> does not.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-224-007d3203d939>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0meli5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPermutationImportance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mperm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPermutationImportance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimputed_X_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_bin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0meli5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimputed_X_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\eli5\\sklearn\\permutation_importance.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \"\"\"\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpandas_available\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    293\u001b[0m                 \u001b[1;34m\"If no scoring is specified, the estimator passed should \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[1;34m\"have a 'score' method. The estimator %r does not.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 % estimator)\n\u001b[0m\u001b[0;32m    296\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         raise ValueError(\"For evaluating multiple scores, use \"\n",
      "\u001b[1;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator <tensorflow.python.keras.engine.sequential.Sequential object at 0x000001BF995417C8> does not."
     ]
    }
   ],
   "source": [
    "#take a look into feature importance\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(model, random_state=1).fit(imputed_X_train,y_train_bin)\n",
    "eli5.show_weights(perm, feature_names = imputed_X_train.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
